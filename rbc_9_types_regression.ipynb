{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbc_9_types_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7uGYKezNag0MbZao3DbOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molcan23/RBC_ks_neural_network/blob/main/rbc_9_types_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN for Coeffitients Prediction"
      ],
      "metadata": {
        "id": "wkRimYzJodfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "nPP36MxloUQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Libraries and packages from Keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "from keras.layers import Dense, LSTM, Dropout, Flatten, Reshape, TimeDistributed, Activation, Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling1D, Bidirectional, ConvLSTM2D, BatchNormalization"
      ],
      "metadata": {
        "id": "DQLiIFZXM35F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting Google Drive"
      ],
      "metadata": {
        "id": "7GETxC1IK0XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "path = '/content/gdrive/MyDrive/phd_UNIZA/simulations_output/'"
      ],
      "metadata": {
        "id": "bvBXR8l9fl8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dbf625-4253-460d-dc3d-7d309598b91c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants and Variables"
      ],
      "metadata": {
        "id": "cMapyH7TK5Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head = [\"cycle\",\n",
        "        \n",
        "        \"rbc_center_position_x\",\n",
        "        \"rbc_center_position_y\",\n",
        "        \"rbc_center_position_z\",\n",
        "        \n",
        "        \"rbc_velocity_x\",\n",
        "        \"rbc_velocity_y\",\n",
        "        \"rbc_velocity_z\",\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_min_z\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "        \"rbc_cuboid_x_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_min_z\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "        \"rbc_cuboid_y_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_z_min_x\",\n",
        "        \"rbc_cuboid_z_min_y\",\n",
        "        \"rbc_cuboid_z_min_z\",\n",
        "        \"rbc_cuboid_z_max_x\",\n",
        "        \"rbc_cuboid_z_max_y\",\n",
        "        \"rbc_cuboid_z_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_x_min_vel_x\",\n",
        "        \"rbc_cuboid_x_min_vel_y\",\n",
        "        \"rbc_cuboid_x_min_vel_z\",\n",
        "        \"rbc_cuboid_x_max_vel_x\",\n",
        "        \"rbc_cuboid_x_max_vel_y\",\n",
        "        \"rbc_cuboid_x_max_vel_z\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_vel_x\",\n",
        "        \"rbc_cuboid_y_min_vel_y\",\n",
        "        \"rbc_cuboid_y_min_vel_z\",\n",
        "        \"rbc_cuboid_y_max_vel_x\",\n",
        "        \"rbc_cuboid_y_max_vel_y\",\n",
        "        \"rbc_cuboid_y_max_vel_z\",\n",
        "\n",
        "        \"rbc_cuboid_z_min_vel_x\",\n",
        "        \"rbc_cuboid_z_min_vel_y\",\n",
        "        \"rbc_cuboid_z_min_vel_z\",\n",
        "        \"rbc_cuboid_z_max_vel_x\",\n",
        "        \"rbc_cuboid_z_max_vel_y\",\n",
        "        \"rbc_cuboid_z_max_vel_z\",\n",
        "\n",
        "        \"volume\",\n",
        "        \"surface\",\n",
        "        \"NaN\" \n",
        "]\n",
        "\n",
        "xy = [        \n",
        "        \"rbc_center_position_x\",\n",
        "        \"rbc_center_position_y\",\n",
        "        \n",
        "        \"rbc_velocity_x\",\n",
        "        \"rbc_velocity_y\",\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "\n",
        "        \"rbc_cuboid_z_min_x\",\n",
        "        \"rbc_cuboid_z_min_y\",\n",
        "        \"rbc_cuboid_z_max_x\",\n",
        "        \"rbc_cuboid_z_max_y\",\n",
        "\n",
        "        \"rbc_cuboid_x_min_vel_x\",\n",
        "        \"rbc_cuboid_x_min_vel_y\",\n",
        "        \"rbc_cuboid_x_max_vel_x\",\n",
        "        \"rbc_cuboid_x_max_vel_y\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_vel_x\",\n",
        "        \"rbc_cuboid_y_min_vel_y\",\n",
        "        \"rbc_cuboid_y_max_vel_x\",\n",
        "        \"rbc_cuboid_y_max_vel_y\",\n",
        "\n",
        "        \"rbc_cuboid_z_min_vel_x\",\n",
        "        \"rbc_cuboid_z_min_vel_y\",\n",
        "        \"rbc_cuboid_z_max_vel_x\",\n",
        "        \"rbc_cuboid_z_max_vel_y\",\n",
        "\n",
        "        \"volume\",\n",
        "        \"surface\",\n",
        "]\n",
        "\n",
        "\n",
        "xy_simple = [        \n",
        "        \"rbc_center_position_x\",\n",
        "        \"rbc_center_position_y\",\n",
        "        \n",
        "        \"rbc_velocity_x\",\n",
        "        \"rbc_velocity_y\",\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "\n",
        "        \"rbc_cuboid_x_min_vel_x\",\n",
        "        \"rbc_cuboid_x_min_vel_y\",\n",
        "        \"rbc_cuboid_x_max_vel_x\",\n",
        "        \"rbc_cuboid_x_max_vel_y\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_vel_x\",\n",
        "        \"rbc_cuboid_y_min_vel_y\",\n",
        "        \"rbc_cuboid_y_max_vel_x\",\n",
        "        \"rbc_cuboid_y_max_vel_y\",\n",
        "]\n",
        "\n",
        "#\n",
        "xy_sized = [\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "        \n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "\n",
        "        'rbc_velocity_x', \n",
        "        'rbc_velocity_y',\n",
        "        'rbc_cuboid_x_min_vel_x',\n",
        "        'rbc_cuboid_x_min_vel_y',\n",
        "        'rbc_cuboid_x_max_vel_x', \n",
        "        'rbc_cuboid_x_max_vel_y',\n",
        "        'rbc_cuboid_y_min_vel_x',\n",
        "        'rbc_cuboid_y_min_vel_y',\n",
        "        'rbc_cuboid_y_max_vel_x', \n",
        "        'rbc_cuboid_y_max_vel_y',\n",
        "        'x_x_size',\n",
        "        'x_y_size',\n",
        "        'y_x_size', \n",
        "        'y_y_size',\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xy_reduced = [\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "        \n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "\n",
        "        'x_x_size',\n",
        "        'y_y_size',\n",
        "]\n",
        "\n",
        "xy_reduced_standardize = [        \n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "        'x_x_size',\n",
        "        'y_y_size',\n",
        "]\n",
        "\n",
        "xy_reduced_normalize = [                      \n",
        "        \"rbc_center_position_x\",\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xz_reduced = [\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_z\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_z\",\n",
        "        \n",
        "        \"rbc_cuboid_z_min_x\",\n",
        "        \"rbc_cuboid_z_min_z\",\n",
        "        \"rbc_cuboid_z_max_x\",\n",
        "        \"rbc_cuboid_z_max_z\",\n",
        "\n",
        "        'x_x_size',\n",
        "        'z_z_size',\n",
        "]\n",
        "\n",
        "xz_reduced_standardize = [        \n",
        "        \"rbc_cuboid_x_min_z\",\n",
        "        \"rbc_cuboid_z_min_z\",\n",
        "        \"rbc_cuboid_x_max_z\",\n",
        "        \"rbc_cuboid_z_max_z\",\n",
        "        'x_x_size',\n",
        "        'z_z_size',\n",
        "]\n",
        "\n",
        "xz_reduced_normalize = [                      \n",
        "        \"rbc_center_position_x\",\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_z_min_x\",\n",
        "        \"rbc_cuboid_z_max_x\",\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xyz_reduced = [\n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_min_z\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "        \"rbc_cuboid_x_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_min_z\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "        \"rbc_cuboid_y_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_z_min_x\",\n",
        "        \"rbc_cuboid_z_min_y\",\n",
        "        \"rbc_cuboid_z_min_z\",\n",
        "        \"rbc_cuboid_z_max_x\",\n",
        "        \"rbc_cuboid_z_max_y\",\n",
        "        \"rbc_cuboid_z_max_z\",\n",
        "       \n",
        "        'x_x_size',\n",
        "        'y_y_size',\n",
        "        'z_z_size',       \n",
        "]\n",
        "\n",
        "xyz_reduced_standardize = [       \n",
        "        \"rbc_cuboid_x_min_y\",\n",
        "        \"rbc_cuboid_x_min_z\",\n",
        "        \"rbc_cuboid_x_max_y\",\n",
        "        \"rbc_cuboid_x_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_y_min_y\",\n",
        "        \"rbc_cuboid_y_min_z\",\n",
        "        \"rbc_cuboid_y_max_y\",\n",
        "        \"rbc_cuboid_y_max_z\",\n",
        "\n",
        "        \"rbc_cuboid_z_min_y\",\n",
        "        \"rbc_cuboid_z_min_z\",\n",
        "        \"rbc_cuboid_z_max_y\",\n",
        "        \"rbc_cuboid_z_max_z\",\n",
        "\n",
        "        'x_x_size',\n",
        "        'y_y_size',\n",
        "        'z_z_size',\n",
        "]\n",
        "\n",
        "xyz_reduced_normalize = [                      \n",
        "        \n",
        "        \"rbc_cuboid_x_min_x\",\n",
        "        \"rbc_cuboid_x_max_x\",\n",
        "        \"rbc_cuboid_y_min_x\",\n",
        "        \"rbc_cuboid_y_max_x\",\n",
        "        \"rbc_cuboid_z_min_x\",\n",
        "        \"rbc_cuboid_z_max_x\",\n",
        "]"
      ],
      "metadata": {
        "id": "hjzpqqvvM43H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SELECTED_AXES = 'xy'\n",
        "SELECTED_COLUMNS = xy_reduced\n",
        "SELECTED_COLUMNS_TO_STANDARDIZE = xy_reduced_standardize\n",
        "SELECTED_COLUMNS_TO_NORMALIZE = xy_reduced_normalize\n",
        "\n",
        "# SELECTED_AXES = 'xz'\n",
        "# SELECTED_COLUMNS = xz_reduced\n",
        "# SELECTED_COLUMNS_TO_STANDARDIZE = xz_reduced_standardize\n",
        "# SELECTED_COLUMNS_TO_NORMALIZE = xz_reduced_normalize\n",
        "\n",
        "# SELECTED_AXES = 'xyz'\n",
        "# SELECTED_COLUMNS = xyz_reduced\n",
        "# SELECTED_COLUMNS_TO_STANDARDIZE = xyz_reduced_standardize\n",
        "# SELECTED_COLUMNS_TO_NORMALIZE = xyz_reduced_normalize\n",
        "\n",
        "# parameters\n",
        "\n",
        "TS_LENGTH = 10\n",
        "NUM_OF_RBC_TYPES = 3\n",
        "LOSS_FN = 'mape'\n",
        "\n",
        "START = 500\n",
        "SAME_SIZE_OF_DF_FROM_SIMULATION = 2700\n",
        "NUMBER_OF_AUGMENTATION = 30\n",
        "\n",
        "SAVE_PATH = f'/content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}'\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "  os.makedirs(SAVE_PATH)\n",
        "\n",
        "STANDARDIZE = True\n",
        "\n",
        "number_of_cells = 54\n",
        "\n",
        "name_of_simulation = 'three_types'"
      ],
      "metadata": {
        "id": "VcvBAzmRQirg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data about one RBC"
      ],
      "metadata": {
        "id": "zHUHB99wLe02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_table(f\"{path}/three_types/rbc0_sim{name_of_simulation}.dat\", sep=\" \", names=head[1:]).drop(['NaN'], axis=1).drop([0], axis=0).astype('float32')\n",
        "df"
      ],
      "metadata": {
        "id": "wzsWq2SaM43I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "43937f0e-4b24-4cdb-f825-e91bda7d4420"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-afdf9834-edf1-4450-96b8-5bd1095c9de0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rbc_center_position_x</th>\n",
              "      <th>rbc_center_position_y</th>\n",
              "      <th>rbc_center_position_z</th>\n",
              "      <th>rbc_velocity_x</th>\n",
              "      <th>rbc_velocity_y</th>\n",
              "      <th>rbc_velocity_z</th>\n",
              "      <th>rbc_cuboid_x_min_x</th>\n",
              "      <th>rbc_cuboid_x_min_y</th>\n",
              "      <th>rbc_cuboid_x_min_z</th>\n",
              "      <th>rbc_cuboid_x_max_x</th>\n",
              "      <th>rbc_cuboid_x_max_y</th>\n",
              "      <th>rbc_cuboid_x_max_z</th>\n",
              "      <th>rbc_cuboid_y_min_x</th>\n",
              "      <th>rbc_cuboid_y_min_y</th>\n",
              "      <th>rbc_cuboid_y_min_z</th>\n",
              "      <th>rbc_cuboid_y_max_x</th>\n",
              "      <th>rbc_cuboid_y_max_y</th>\n",
              "      <th>rbc_cuboid_y_max_z</th>\n",
              "      <th>rbc_cuboid_z_min_x</th>\n",
              "      <th>rbc_cuboid_z_min_y</th>\n",
              "      <th>rbc_cuboid_z_min_z</th>\n",
              "      <th>rbc_cuboid_z_max_x</th>\n",
              "      <th>rbc_cuboid_z_max_y</th>\n",
              "      <th>rbc_cuboid_z_max_z</th>\n",
              "      <th>rbc_cuboid_x_min_vel_x</th>\n",
              "      <th>rbc_cuboid_x_min_vel_y</th>\n",
              "      <th>rbc_cuboid_x_min_vel_z</th>\n",
              "      <th>rbc_cuboid_x_max_vel_x</th>\n",
              "      <th>rbc_cuboid_x_max_vel_y</th>\n",
              "      <th>rbc_cuboid_x_max_vel_z</th>\n",
              "      <th>rbc_cuboid_y_min_vel_x</th>\n",
              "      <th>rbc_cuboid_y_min_vel_y</th>\n",
              "      <th>rbc_cuboid_y_min_vel_z</th>\n",
              "      <th>rbc_cuboid_y_max_vel_x</th>\n",
              "      <th>rbc_cuboid_y_max_vel_y</th>\n",
              "      <th>rbc_cuboid_y_max_vel_z</th>\n",
              "      <th>rbc_cuboid_z_min_vel_x</th>\n",
              "      <th>rbc_cuboid_z_min_vel_y</th>\n",
              "      <th>rbc_cuboid_z_min_vel_z</th>\n",
              "      <th>rbc_cuboid_z_max_vel_x</th>\n",
              "      <th>rbc_cuboid_z_max_vel_y</th>\n",
              "      <th>rbc_cuboid_z_max_vel_z</th>\n",
              "      <th>volume</th>\n",
              "      <th>surface</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>32.448399</td>\n",
              "      <td>13.062350</td>\n",
              "      <td>8.326485</td>\n",
              "      <td>0.020506</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>-0.000026</td>\n",
              "      <td>28.554800</td>\n",
              "      <td>12.719492</td>\n",
              "      <td>8.285869</td>\n",
              "      <td>36.368404</td>\n",
              "      <td>13.407907</td>\n",
              "      <td>8.369804</td>\n",
              "      <td>32.059891</td>\n",
              "      <td>9.185813</td>\n",
              "      <td>8.724632</td>\n",
              "      <td>32.821655</td>\n",
              "      <td>16.939314</td>\n",
              "      <td>7.927630</td>\n",
              "      <td>30.791706</td>\n",
              "      <td>15.249967</td>\n",
              "      <td>6.763115</td>\n",
              "      <td>34.085606</td>\n",
              "      <td>10.879069</td>\n",
              "      <td>9.887869</td>\n",
              "      <td>0.020451</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.000873</td>\n",
              "      <td>0.020697</td>\n",
              "      <td>-0.000762</td>\n",
              "      <td>-0.000963</td>\n",
              "      <td>0.019168</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.021486</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>0.019848</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>-6.130968e-05</td>\n",
              "      <td>0.020857</td>\n",
              "      <td>-0.000403</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>90.728622</td>\n",
              "      <td>133.005615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4000</th>\n",
              "      <td>34.763180</td>\n",
              "      <td>13.062197</td>\n",
              "      <td>8.329570</td>\n",
              "      <td>0.024739</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>30.879749</td>\n",
              "      <td>12.825916</td>\n",
              "      <td>8.402707</td>\n",
              "      <td>38.678356</td>\n",
              "      <td>13.301639</td>\n",
              "      <td>8.254764</td>\n",
              "      <td>34.916428</td>\n",
              "      <td>9.194132</td>\n",
              "      <td>8.743280</td>\n",
              "      <td>34.572685</td>\n",
              "      <td>16.936342</td>\n",
              "      <td>7.917813</td>\n",
              "      <td>33.053715</td>\n",
              "      <td>15.306187</td>\n",
              "      <td>6.765472</td>\n",
              "      <td>36.432110</td>\n",
              "      <td>10.825032</td>\n",
              "      <td>9.906028</td>\n",
              "      <td>0.025012</td>\n",
              "      <td>0.001293</td>\n",
              "      <td>0.001349</td>\n",
              "      <td>0.024474</td>\n",
              "      <td>-0.001258</td>\n",
              "      <td>-0.001260</td>\n",
              "      <td>0.023335</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.026036</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.024352</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>1.295938e-04</td>\n",
              "      <td>0.024998</td>\n",
              "      <td>-0.000636</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>90.718575</td>\n",
              "      <td>132.973907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6000</th>\n",
              "      <td>37.292320</td>\n",
              "      <td>13.066747</td>\n",
              "      <td>8.337736</td>\n",
              "      <td>0.025618</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>33.448631</td>\n",
              "      <td>12.965900</td>\n",
              "      <td>8.546241</td>\n",
              "      <td>41.166508</td>\n",
              "      <td>13.170130</td>\n",
              "      <td>8.127045</td>\n",
              "      <td>37.307648</td>\n",
              "      <td>9.195539</td>\n",
              "      <td>8.754022</td>\n",
              "      <td>37.233997</td>\n",
              "      <td>16.945356</td>\n",
              "      <td>7.925404</td>\n",
              "      <td>36.339161</td>\n",
              "      <td>15.426981</td>\n",
              "      <td>6.787828</td>\n",
              "      <td>38.195721</td>\n",
              "      <td>10.717277</td>\n",
              "      <td>9.908830</td>\n",
              "      <td>0.026115</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>-0.001339</td>\n",
              "      <td>-0.001280</td>\n",
              "      <td>0.024262</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.025484</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>9.436736e-05</td>\n",
              "      <td>0.025702</td>\n",
              "      <td>-0.000324</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>90.728790</td>\n",
              "      <td>132.851089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8000</th>\n",
              "      <td>39.864815</td>\n",
              "      <td>13.073532</td>\n",
              "      <td>8.345613</td>\n",
              "      <td>0.025785</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>36.009552</td>\n",
              "      <td>12.521410</td>\n",
              "      <td>7.829638</td>\n",
              "      <td>43.750366</td>\n",
              "      <td>13.630875</td>\n",
              "      <td>8.854249</td>\n",
              "      <td>39.745789</td>\n",
              "      <td>9.196630</td>\n",
              "      <td>8.767933</td>\n",
              "      <td>39.939346</td>\n",
              "      <td>16.957733</td>\n",
              "      <td>7.928006</td>\n",
              "      <td>38.907269</td>\n",
              "      <td>15.475667</td>\n",
              "      <td>6.803061</td>\n",
              "      <td>40.769203</td>\n",
              "      <td>10.685130</td>\n",
              "      <td>9.913312</td>\n",
              "      <td>0.025443</td>\n",
              "      <td>0.001483</td>\n",
              "      <td>0.001499</td>\n",
              "      <td>0.026123</td>\n",
              "      <td>-0.001353</td>\n",
              "      <td>-0.001367</td>\n",
              "      <td>0.024448</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.027112</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>0.025824</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>2.049291e-04</td>\n",
              "      <td>0.025724</td>\n",
              "      <td>-0.000314</td>\n",
              "      <td>-0.000044</td>\n",
              "      <td>90.746056</td>\n",
              "      <td>132.702469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>42.444984</td>\n",
              "      <td>13.081062</td>\n",
              "      <td>8.351546</td>\n",
              "      <td>0.025809</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>38.570034</td>\n",
              "      <td>12.672924</td>\n",
              "      <td>7.982332</td>\n",
              "      <td>46.350914</td>\n",
              "      <td>13.494288</td>\n",
              "      <td>8.716006</td>\n",
              "      <td>42.192467</td>\n",
              "      <td>9.199048</td>\n",
              "      <td>8.782172</td>\n",
              "      <td>42.652363</td>\n",
              "      <td>16.969049</td>\n",
              "      <td>7.925220</td>\n",
              "      <td>43.000740</td>\n",
              "      <td>15.600653</td>\n",
              "      <td>6.800741</td>\n",
              "      <td>43.336765</td>\n",
              "      <td>10.654060</td>\n",
              "      <td>9.901152</td>\n",
              "      <td>0.025741</td>\n",
              "      <td>0.001518</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.025888</td>\n",
              "      <td>-0.001382</td>\n",
              "      <td>-0.001404</td>\n",
              "      <td>0.024471</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.027141</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.025926</td>\n",
              "      <td>-0.000146</td>\n",
              "      <td>-2.877278e-05</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>-0.000307</td>\n",
              "      <td>-0.000195</td>\n",
              "      <td>90.765503</td>\n",
              "      <td>132.547821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7626000</th>\n",
              "      <td>11909.727539</td>\n",
              "      <td>12.986670</td>\n",
              "      <td>12.614756</td>\n",
              "      <td>0.033824</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>11905.827148</td>\n",
              "      <td>12.933554</td>\n",
              "      <td>12.014547</td>\n",
              "      <td>11913.651367</td>\n",
              "      <td>13.033231</td>\n",
              "      <td>13.214984</td>\n",
              "      <td>11908.879883</td>\n",
              "      <td>10.513412</td>\n",
              "      <td>15.038949</td>\n",
              "      <td>11910.497070</td>\n",
              "      <td>15.525931</td>\n",
              "      <td>10.253169</td>\n",
              "      <td>11909.404297</td>\n",
              "      <td>14.048412</td>\n",
              "      <td>9.002452</td>\n",
              "      <td>11909.977539</td>\n",
              "      <td>11.993466</td>\n",
              "      <td>16.269367</td>\n",
              "      <td>0.033824</td>\n",
              "      <td>0.000655</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>0.033867</td>\n",
              "      <td>-0.000640</td>\n",
              "      <td>-0.001854</td>\n",
              "      <td>0.034590</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.033085</td>\n",
              "      <td>-0.000176</td>\n",
              "      <td>-0.000292</td>\n",
              "      <td>0.032208</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>-6.522826e-07</td>\n",
              "      <td>0.035479</td>\n",
              "      <td>-0.000149</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>90.700394</td>\n",
              "      <td>133.118042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7628000</th>\n",
              "      <td>11913.110352</td>\n",
              "      <td>12.988057</td>\n",
              "      <td>12.623236</td>\n",
              "      <td>0.033837</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>11909.215820</td>\n",
              "      <td>12.998795</td>\n",
              "      <td>12.212664</td>\n",
              "      <td>11917.033203</td>\n",
              "      <td>12.971344</td>\n",
              "      <td>13.032394</td>\n",
              "      <td>11912.340820</td>\n",
              "      <td>10.528305</td>\n",
              "      <td>15.078862</td>\n",
              "      <td>11913.804688</td>\n",
              "      <td>15.508088</td>\n",
              "      <td>10.225223</td>\n",
              "      <td>11912.625977</td>\n",
              "      <td>14.057606</td>\n",
              "      <td>9.006082</td>\n",
              "      <td>11913.524414</td>\n",
              "      <td>11.979205</td>\n",
              "      <td>16.276485</td>\n",
              "      <td>0.033939</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.001992</td>\n",
              "      <td>0.033770</td>\n",
              "      <td>-0.000601</td>\n",
              "      <td>-0.001801</td>\n",
              "      <td>0.034625</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.033074</td>\n",
              "      <td>-0.000179</td>\n",
              "      <td>-0.000266</td>\n",
              "      <td>0.032237</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>7.373190e-05</td>\n",
              "      <td>0.035469</td>\n",
              "      <td>-0.000137</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>90.712791</td>\n",
              "      <td>133.026611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7630000</th>\n",
              "      <td>11916.495117</td>\n",
              "      <td>12.990432</td>\n",
              "      <td>12.632465</td>\n",
              "      <td>0.033856</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>11912.616211</td>\n",
              "      <td>13.062707</td>\n",
              "      <td>12.409122</td>\n",
              "      <td>11920.406250</td>\n",
              "      <td>12.912930</td>\n",
              "      <td>12.853148</td>\n",
              "      <td>11915.805664</td>\n",
              "      <td>10.544847</td>\n",
              "      <td>15.117166</td>\n",
              "      <td>11917.111328</td>\n",
              "      <td>15.489755</td>\n",
              "      <td>10.199594</td>\n",
              "      <td>11915.851562</td>\n",
              "      <td>14.066795</td>\n",
              "      <td>9.016870</td>\n",
              "      <td>11917.072266</td>\n",
              "      <td>11.966439</td>\n",
              "      <td>16.277010</td>\n",
              "      <td>0.034059</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.033682</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>-0.001777</td>\n",
              "      <td>0.034667</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>0.033066</td>\n",
              "      <td>-0.000186</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>0.032267</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>1.409786e-04</td>\n",
              "      <td>0.035471</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>90.725372</td>\n",
              "      <td>132.935532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7632000</th>\n",
              "      <td>11919.881836</td>\n",
              "      <td>12.993839</td>\n",
              "      <td>12.642283</td>\n",
              "      <td>0.033882</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>11916.014648</td>\n",
              "      <td>12.466342</td>\n",
              "      <td>12.117672</td>\n",
              "      <td>11923.782227</td>\n",
              "      <td>13.511371</td>\n",
              "      <td>13.167985</td>\n",
              "      <td>11919.275391</td>\n",
              "      <td>10.563148</td>\n",
              "      <td>15.153748</td>\n",
              "      <td>11920.417969</td>\n",
              "      <td>15.470967</td>\n",
              "      <td>10.176159</td>\n",
              "      <td>11919.080078</td>\n",
              "      <td>14.075907</td>\n",
              "      <td>9.034683</td>\n",
              "      <td>11920.619141</td>\n",
              "      <td>11.955351</td>\n",
              "      <td>16.271051</td>\n",
              "      <td>0.033773</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>0.034007</td>\n",
              "      <td>-0.000534</td>\n",
              "      <td>-0.001732</td>\n",
              "      <td>0.034718</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.033062</td>\n",
              "      <td>-0.000192</td>\n",
              "      <td>-0.000225</td>\n",
              "      <td>0.032303</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>2.127479e-04</td>\n",
              "      <td>0.035477</td>\n",
              "      <td>-0.000102</td>\n",
              "      <td>-0.000090</td>\n",
              "      <td>90.737923</td>\n",
              "      <td>132.845383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7634000</th>\n",
              "      <td>11923.271484</td>\n",
              "      <td>12.998240</td>\n",
              "      <td>12.652589</td>\n",
              "      <td>0.033914</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>11919.399414</td>\n",
              "      <td>12.527761</td>\n",
              "      <td>12.309568</td>\n",
              "      <td>11927.178711</td>\n",
              "      <td>13.459425</td>\n",
              "      <td>12.995620</td>\n",
              "      <td>11922.750000</td>\n",
              "      <td>10.583344</td>\n",
              "      <td>15.188618</td>\n",
              "      <td>11923.724609</td>\n",
              "      <td>15.451660</td>\n",
              "      <td>10.154828</td>\n",
              "      <td>11923.117188</td>\n",
              "      <td>13.832065</td>\n",
              "      <td>9.042397</td>\n",
              "      <td>11923.369141</td>\n",
              "      <td>12.204206</td>\n",
              "      <td>16.284681</td>\n",
              "      <td>0.033931</td>\n",
              "      <td>0.000622</td>\n",
              "      <td>0.001955</td>\n",
              "      <td>0.033929</td>\n",
              "      <td>-0.000505</td>\n",
              "      <td>-0.001709</td>\n",
              "      <td>0.034777</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.033062</td>\n",
              "      <td>-0.000195</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>0.032289</td>\n",
              "      <td>-0.000033</td>\n",
              "      <td>-1.024825e-04</td>\n",
              "      <td>0.035550</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>90.750534</td>\n",
              "      <td>132.757492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3817 rows Ã— 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afdf9834-edf1-4450-96b8-5bd1095c9de0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afdf9834-edf1-4450-96b8-5bd1095c9de0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afdf9834-edf1-4450-96b8-5bd1095c9de0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         rbc_center_position_x  rbc_center_position_y  ...     volume     surface\n",
              "2000                 32.448399              13.062350  ...  90.728622  133.005615\n",
              "4000                 34.763180              13.062197  ...  90.718575  132.973907\n",
              "6000                 37.292320              13.066747  ...  90.728790  132.851089\n",
              "8000                 39.864815              13.073532  ...  90.746056  132.702469\n",
              "10000                42.444984              13.081062  ...  90.765503  132.547821\n",
              "...                        ...                    ...  ...        ...         ...\n",
              "7626000           11909.727539              12.986670  ...  90.700394  133.118042\n",
              "7628000           11913.110352              12.988057  ...  90.712791  133.026611\n",
              "7630000           11916.495117              12.990432  ...  90.725372  132.935532\n",
              "7632000           11919.881836              12.993839  ...  90.737923  132.845383\n",
              "7634000           11923.271484              12.998240  ...  90.750534  132.757492\n",
              "\n",
              "[3817 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for boxplot graph"
      ],
      "metadata": {
        "id": "kFuf2swmLmrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_difference(y_hat, y):\n",
        "  return np.abs(((y_hat - y) / y) * 100)"
      ],
      "metadata": {
        "id": "f9j9rWrLHQBK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def absolute_error(y_hat, y):\n",
        "  return np.abs(y_hat - y)"
      ],
      "metadata": {
        "id": "pFBixdNXb05c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_for_plot(pred, real):\n",
        "\n",
        "  dir_labels = {}\n",
        "  diff_fun = percentage_difference\n",
        "\n",
        "  for i, j in zip(predictions_future, y_test):\n",
        "    if str(j) in dir_labels.keys():\n",
        "      dir_labels[str(j)].append(diff_fun(i[0], j))\n",
        "    else:\n",
        "      dir_labels[str(j)] = [diff_fun(i[0], j)]\n",
        "\n",
        "  return [dir_labels[x] for x in sorted(dir_labels.keys())], dir_labels\n"
      ],
      "metadata": {
        "id": "UZRGncFw8Px6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ks_boxplots(data, name, dir_labels, outliers): \n",
        "    fig = plt.figure(figsize =(10, 7))\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    bp = ax.boxplot(data, showfliers=outliers, showmeans=True)\n",
        "\n",
        "    plt.title('Absolute Percentage Error by True Value of ks')\n",
        "    ax.set_xlabel('Value of ks')\n",
        "    ax.set_ylabel('Absolute Percentage Error')\n",
        "    ax.set_xticklabels(labels=sorted(dir_labels.keys()))\n",
        "    ax.grid()\n",
        "\n",
        "    for i in range(len(data)):\n",
        "      y = data[i]\n",
        "      x = np.random.normal(i, 0.02, len(y))\n",
        "      plt.plot(x+1, y, 'r.', alpha=0.2)\n",
        "\n",
        "    plt.savefig(f'{SAVE_PATH}/{name}.png')\n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure(figsize =(10, 7))\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    bp = ax.boxplot(data, showfliers=outliers, showmeans=True)\n",
        "\n",
        "    plt.title('Absolute Percentage Error by True Value of ks')\n",
        "    ax.set_xlabel('Value of ks')\n",
        "    ax.set_ylabel('Absolute Percentage Error')\n",
        "    ax.set_xticklabels(labels=sorted(dir_labels.keys()))\n",
        "    ax.grid()\n",
        "\n",
        "    plt.savefig(f'{SAVE_PATH}/{name}_NO.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ot4wwAcDG-Jn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming data into dataset\n",
        "\n",
        "- format \n",
        "- augmentation\n",
        "- saving on Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "uEsU4UzGhaXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_columns(df, cols):\n",
        "    for c in cols:\n",
        "        df[c] = (df[c] - df[c].mean(axis=0)) / df[c].std(axis=0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "7mkoLz20ktCF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation(x, gaussian_noise_level=.001, offset_noise_level=.5):\n",
        "        noise        = gaussian_noise_level * tf.random.normal(x.shape)\n",
        "        offset_noise = 2.  * tf.random.uniform(x.shape) - 1.0\n",
        "        x_result     = tf.convert_to_tensor(x) + noise + offset_noise_level * offset_noise\n",
        "        return x_result"
      ],
      "metadata": {
        "id": "GzNAqVzoIMbl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_examples(df, target, ts_length=10, selected_columns=xy_reduced, number_of_augmentation=10):\n",
        "  \"\"\"\n",
        "  Split df into timeseries with length=ts_length and add target value to each mini-timeseries\n",
        "  \"\"\"\n",
        "  training_data = []\n",
        "  target_data = []\n",
        "\n",
        "  for i in range(ts_length, df.shape[0], ts_length):\n",
        "    sample = df.iloc[i-ts_length:i, :] \n",
        "\n",
        "    for field in SELECTED_COLUMNS_TO_NORMALIZE:\n",
        "      sample[field] = sample[field].subtract(sample[field].min())\n",
        "        \n",
        "    sample = tf.convert_to_tensor(sample[SELECTED_COLUMNS])\n",
        "    training_data.append(sample)\n",
        "    target_data.append(target)\n",
        "\n",
        "    for _ in range(number_of_augmentation):\n",
        "      training_data.append(augmentation(sample))\n",
        "      target_data.append(target)\n",
        "\n",
        "  return training_data, target_data\n",
        "\n",
        "# df = pd.read_table(f\"{path}rbc0_sim{name_of_simulation}.dat\", sep=\" \", names=head[1:]).drop(['NaN'], axis=1).drop([0], axis=0).astype('float32')\n",
        "\n",
        "# # calculation of height and width\n",
        "# for ax1 in ['x', 'y', 'z']:\n",
        "#       for ax2 in ['x', 'y', 'z']:\n",
        "#         df[f'{ax1}_{ax2}_size'] = df[f'rbc_cuboid_{ax1}_max_{ax2}'] - df[f'rbc_cuboid_{ax1}_min_{ax2}']\n",
        "\n",
        "# trd, tad = create_training_examples(df, 0, ts_length=3, number_of_augmentation=0)\n",
        "# print(pd.DataFrame(np.array(trd[0])))\n",
        "# print(pd.DataFrame(np.array(trd[1])))\n",
        "# print(pd.DataFrame(np.array(trd[2])))\n",
        "\n",
        "# # pd.concat([pd.DataFrame(np.array(trd[0])), pd.DataFrame(np.array(trd[1]))], ignore_index=True)"
      ],
      "metadata": {
        "id": "6C8jtwZxv9X3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next cell is commented due to unneccery execution. Needs to be runed only once per dataset. (long executio)"
      ],
      "metadata": {
        "id": "9cILvEvRNMpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # create datasets from dat files (at this point files are located in '.' folder)\n",
        "\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/gdrive/')\n",
        "\n",
        "# # path = '/content/gdrive/MyDrive/phd_UNIZA/simulations_output/three_types/'\n",
        "# # df = pd.read_table(f\"{path}/three_types/rbc0_sim{name_of_simulation}.dat\", sep=\" \", names=head[1:]).drop(['NaN'], axis=1).drop([0], axis=0).astype('float32')\n",
        "\n",
        "# training_data1 = []\n",
        "# target_data1 = []\n",
        "\n",
        "# df_all = pd.DataFrame()\n",
        "# rbc_coeffitients = []\n",
        "# number_of_cells = 0\n",
        "\n",
        "# for simulation, coef in zip(['three_types', 'another_three_types', 'gap_three'],\n",
        "#                             [[.3, .005, .03],\n",
        "#                              [.15, .015, .009], \n",
        "#                              [.225, .1, .05]]):\n",
        "    \n",
        "#     full_path = f\"{path}/{simulation}\"\n",
        "#     only_cell_files = sorted([f for f in listdir(full_path) if re.match(\"rbc[0-9]+_.+.dat\", f)])\n",
        "#     number_of_cells += len(only_cell_files)\n",
        "\n",
        "#     for i, file_ in enumerate(only_cell_files):\n",
        "#       # print(file_)\n",
        "#       df = pd.read_table(f\"{full_path}/{file_}\", sep=\" \", names=head[1:]).drop(['NaN'], axis=1).drop([0], axis=0)[START:SAME_SIZE_OF_DF_FROM_SIMULATION]\n",
        "#       df = df.astype('float32')\n",
        "#       df_all = pd.concat([df_all, df], ignore_index=True)\n",
        "#       if re.match(f\"(rbc0_|rbc1_|rbc2_|rbc3_|rbc4_|rbc5_).*\", file_):\n",
        "#         rbc_coeffitients.append(coef[0])\n",
        "#       elif re.match(f\"(rbc6_|rbc7_|rbc8_|rbc9_|rbc10_|rbc11_).*\", file_):\n",
        "#         rbc_coeffitients.append(coef[1])\n",
        "#       else:\n",
        "#         rbc_coeffitients.append(coef[2])\n",
        "\n",
        "# # calculation of RBC height and width\n",
        "# for ax1 in ['x', 'y', 'z']:\n",
        "#       for ax2 in ['x', 'y', 'z']:\n",
        "#         df_all[f'{ax1}_{ax2}_size'] = df_all[f'rbc_cuboid_{ax1}_max_{ax2}'] - df_all[f'rbc_cuboid_{ax1}_min_{ax2}']\n",
        "\n",
        "# if STANDARDIZE:\n",
        "#     df_all = standardize_columns(df_all, cols=SELECTED_COLUMNS_TO_STANDARDIZE)\n",
        "#     df_all\n",
        "\n",
        "# dataset_path = f'/content/gdrive/MyDrive/phd_UNIZA/simulations_output/dataset/W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}'\n",
        "# if not os.path.exists(dataset_path):\n",
        "#   os.makedirs(dataset_path)\n",
        "\n",
        "# for i in range(0, number_of_cells):  # 52  # 48\n",
        "#     print(i, \"/\", 54)\n",
        "#     trd, tad = create_training_examples(df_all[i*(SAME_SIZE_OF_DF_FROM_SIMULATION - START):(i+1)*(SAME_SIZE_OF_DF_FROM_SIMULATION - START)],\n",
        "#                                         rbc_coeffitients[i],\n",
        "#                                         TS_LENGTH,\n",
        "#                                         selected_columns=SELECTED_COLUMNS,\n",
        "#                                         number_of_augmentation=NUMBER_OF_AUGMENTATION)\n",
        "#     data_out = f'{dataset_path}/data_time_series_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}_rbc_{str(i)}.npy'\n",
        "#     label_out = f'{dataset_path}/data_labels_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}_rbc_{str(i)}.npy'\n",
        "\n",
        "#     np.save(data_out, np.array(trd))\n",
        "#     np.save(label_out, np.array(tad))\n",
        "\n",
        "#     training_data1 = training_data1 + trd\n",
        "#     target_data1 = target_data1 + tad\n"
      ],
      "metadata": {
        "id": "ct5VKdLjhouY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset from Drive"
      ],
      "metadata": {
        "id": "NStctrHOMdbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = f'/content/gdrive/MyDrive/phd_UNIZA/simulations_output/dataset/W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}'\n",
        "\n",
        "training_data1 = np.empty([1, TS_LENGTH, len(SELECTED_COLUMNS)], dtype=float)\n",
        "target_data1 = []\n",
        "\n",
        "for i in range(number_of_cells):  # 52  # 48\n",
        "    # print(i, \"/\", 54)\n",
        "    data_out = f'{dataset_path}/data_time_series_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}_rbc_{str(i)}.npy'\n",
        "    label_out = f'{dataset_path}/data_labels_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_X_{SELECTED_AXES}_rbc_{str(i)}.npy'\n",
        "      \n",
        "    trd = np.load(data_out)\n",
        "    tad = np.load(label_out)\n",
        "    print(trd.shape)\n",
        "    training_data1 = np.append(training_data1, trd, axis=0)\n",
        "    target_data1 = np.append(target_data1, tad, axis=0)\n",
        "\n",
        "training_data1 = np.delete(training_data1, 0, axis=0)"
      ],
      "metadata": {
        "id": "wzpH0NSzBmOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0deb67-bb98-4bd0-a505-331d0238bd68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n",
            "(6789, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming dataset"
      ],
      "metadata": {
        "id": "oBRhBbjhYbEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.array(training_data1)\n",
        "\n",
        "target_data = np.array(target_data1)"
      ],
      "metadata": {
        "id": "v8a0DRYiJWS6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0]"
      ],
      "metadata": {
        "id": "OtjWTaVT6Z9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478e321a-a050-4e0b-b2c3-bb090095b02c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        , -1.10436714,  0.        , -0.82278812,  0.        ,\n",
              "        -1.07624531,  0.        , -0.80722463, -0.99481142,  1.08799386],\n",
              "       [ 3.17895508, -1.07659841,  2.99475098, -0.76707798,  3.16223145,\n",
              "        -1.0596621 ,  3.04833984, -0.82848489, -1.07614803,  0.93124396],\n",
              "       [ 6.33776855, -1.18933988,  6.02355957, -0.60998887,  6.56311035,\n",
              "        -1.04238558,  5.84204102, -0.84899521, -1.13355255,  0.77474838],\n",
              "       [ 9.42858887, -1.17297888,  9.13879395, -0.63796186,  9.41308594,\n",
              "        -1.02924287,  9.17028809, -0.86935127, -1.12277246,  0.63595217],\n",
              "       [12.47033691, -1.25067127, 12.26794434, -0.63390362, 12.29968262,\n",
              "        -1.01819026, 12.44042969, -0.88710845, -1.08417928,  0.51657695],\n",
              "       [15.41040039, -1.17100167, 15.4786377 , -0.66282767, 15.22192383,\n",
              "        -1.00960326, 15.6517334 , -0.90178204, -0.96468073,  0.42018583],\n",
              "       [18.34631348, -1.15185773, 18.67773438, -0.69732499, 18.17553711,\n",
              "        -1.00302327, 18.55529785, -0.91052759, -0.84847015,  0.35670283],\n",
              "       [21.30456543, -1.09015083, 21.85827637, -0.78655112, 21.44042969,\n",
              "        -0.99819964, 21.59716797, -0.91677099, -0.75031638,  0.31086183],\n",
              "       [24.25415039, -1.06776845, 25.01391602, -0.81461251, 24.52307129,\n",
              "        -0.99594879, 24.62280273, -0.92072135, -0.6593315 ,  0.28516299],\n",
              "       [27.23901367, -1.00824952, 28.14318848, -0.88834673, 27.63171387,\n",
              "        -0.99365318, 27.64050293, -0.9222014 , -0.59556657,  0.2695418 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping for CNN\n",
        "training_data_CNN = np.reshape(training_data, [training_data.shape[0], training_data.shape[1], training_data.shape[2], 1])"
      ],
      "metadata": {
        "id": "wjeyuWj1WSlH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train shape == {}.'.format(training_data.shape))\n",
        "\n",
        "print('X_train shape == {}.'.format(training_data_CNN.shape))\n",
        "print('y_train shape == {}.'.format(target_data.shape))\n",
        "\n",
        "print(type(training_data))\n",
        "print(type(training_data_CNN))"
      ],
      "metadata": {
        "id": "Ujq8j_IfOLPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2b1cfc-4752-4849-b3ee-d4ce6b743b51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape == (366606, 10, 10).\n",
            "X_train shape == (366606, 10, 10, 1).\n",
            "y_train shape == (366606,).\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(training_data, target_data, test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "KFStylVsM43J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_CNN, X_test_CNN, y_train_CNN, y_test_CNN = sklearn.model_selection.train_test_split(training_data_CNN, target_data, test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "p9gAcdFcWIhZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    X_train, y_train, TS_LENGTH, sequence_stride=10, sampling_rate=1,\n",
        "    batch_size=32, shuffle=False, seed=None, start_index=None, end_index=None\n",
        ")\n",
        "\n",
        "for batch in dataset:\n",
        "  inputs, targets = batch\n",
        "  print(inputs.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFPvl8R4DRif",
        "outputId": "3eb5151e-0689-4e6c-91b2-6b32c8d4faa5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Plotting function for training\n",
        "\n",
        "Accuracy and loss plots"
      ],
      "metadata": {
        "id": "20mCRv3nPdxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "# from sklearn.metrics import r2_score\n",
        "\n",
        "def r2_keras(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred )) \n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "metadata": {
        "id": "IwvGgVe2frhJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_acc_loss(history, name=\"\"):\n",
        "\n",
        "    # if os.path.exists(\"./plots\"):\n",
        "    #     os.makedirs(\"./plots\")\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    # try:\n",
        "    #   plt.plot(history.history['mean_squared_error'])\n",
        "    #   plt.plot(history.history['val_mean_squared_error'])\n",
        "    #   plt.title('model mean_squared_error')\n",
        "    #   plt.ylabel('mean_squared_error')\n",
        "    #   plt.xlabel('epoch')\n",
        "    #   plt.legend(['train', 'validation'], loc='upper left')\n",
        "    #   plt.savefig(f'{name}_model_mean_squared_error.png')\n",
        "    #   plt.show()\n",
        "    # except:\n",
        "    #   try:\n",
        "    #     plt.plot(history.history['mean_absolute_error'])\n",
        "    #     plt.plot(history.history['val_mean_absolute_error'])\n",
        "    #     plt.title('model mean_absolute_error')\n",
        "    #     plt.ylabel('mean_absolute_error')\n",
        "    #     plt.xlabel('epoch')\n",
        "    #     plt.legend(['train', 'validation'], loc='upper left')\n",
        "    #     plt.savefig(f'{name}_model_mean_absolute_error.png')\n",
        "    #     plt.show()\n",
        "    #   except:  # mean_absolute_percentage_error\n",
        "    plt.plot(history.history['r2_keras'])\n",
        "    plt.plot(history.history['val_r2_keras'])\n",
        "    plt.title('r2_keras')\n",
        "    plt.ylabel('mean_absolute_percentage_error')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.savefig(f'{SAVE_PATH}/{name}_model_r2_keras.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.savefig(f'{SAVE_PATH}/{name}_model_loss.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vrZtzqt4Q1nX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File for saving mean absolut percentage error and loss"
      ],
      "metadata": {
        "id": "49Q0gMovztRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_file = open(f'{SAVE_PATH}/statistics.txt', \"a\")\n",
        "out_file.write(\"STATISTICS\\n\\n\\n\")\n",
        "out_file.close()"
      ],
      "metadata": {
        "id": "Kr_UEv81zsgp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Regression NN trained on 9 types of ks coeffitcient of RBC"
      ],
      "metadata": {
        "id": "9RhYDxz9hor1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Dense model\n",
        "\n",
        "Using only Dense layers\n"
      ],
      "metadata": {
        "id": "v6L5NMAHBXt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def dense_model(number_of_classes=2, learning_rate=1e-4, input_shape=None):\n",
        "#   model = Sequential()\n",
        "#   model.add(Flatten())\n",
        "#   model.add(Dense(256, 'relu'))\n",
        "#   model.add(Dropout(0.25))\n",
        "#   model.add(Dense(128, 'relu'))\n",
        "#   model.add(Dropout(0.25))\n",
        "#   model.add(Dense(units=2, activation='softmax'))\n",
        "#   model.compile(loss='categorical_crossentropy',\n",
        "#                 optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "#                 metrics=['accuracy'])\n",
        "  \n",
        "#   return model"
      ],
      "metadata": {
        "id": "JrjNSJFmPQcZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM simple model"
      ],
      "metadata": {
        "id": "UpkaHl-75kft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QEfIfwQkoSiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_model(learning_rate=1e-4, input_shape=None):\n",
        "    model = Sequential([\n",
        "        LSTM(\n",
        "            units=256,\n",
        "            return_sequences=True, \n",
        "            input_shape=(input_shape),\n",
        "            # kernel_initializer='random_normal',\n",
        "            kernel_initializer = tf.keras.initializers.GlorotNormal(seed=None),\n",
        "            bias_initializer='zeros'\n",
        "        ),\n",
        "        Dropout(0.1),\n",
        "        LSTM(units=64, return_sequences=True),\n",
        "        Dropout(0.1),\n",
        "        LSTM(units=32, return_sequences=True),\n",
        "        Dropout(0.1),\n",
        "        LSTM(units=10, return_sequences=True),\n",
        "        Flatten(),\n",
        "        Dropout(0.1),\n",
        "        Dense(512),\n",
        "        Dropout(0.1),\n",
        "        Dense(256),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    # loss_f = tf.keras.losses.MeanSquaredError()\n",
        "    # loss_f = tf.keras.losses.MeanAbsoluteError()\n",
        "    loss_f = tf.keras.losses.MeanAbsolutePercentageError()\n",
        "    # loss_f = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "    \n",
        "    # lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    #     initial_learning_rate=1e-2,\n",
        "    #     decay_steps=10000,\n",
        "    #     decay_rate=0.9\n",
        "    # )\n",
        "\n",
        "    model.compile(\n",
        "      loss=loss_f,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "      metrics=[r2_keras]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "PGaFyeQhy2ih"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = LSTM_model(learning_rate=1e-4, input_shape=X_train[0].shape)"
      ],
      "metadata": {
        "id": "JdxMOMgh3D7V"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath=f'{SAVE_PATH}/weights_LSTM_{TS_LENGTH}.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history_1 = model_1.fit(X_train, y_train, shuffle=True, epochs=EPOCHS, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIMYMcC_M43J",
        "outputId": "1216d1b9-1a3b-4519-c7bd-3a574759e900"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 66.2452 - r2_keras: -0.4925\n",
            "Epoch 00001: val_loss improved from inf to 51.00063, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 179s 167ms/step - loss: 66.2452 - r2_keras: -0.4925 - val_loss: 51.0006 - val_r2_keras: 0.1978 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 47.2084 - r2_keras: 0.2708\n",
            "Epoch 00002: val_loss improved from 51.00063 to 46.32664, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 169s 164ms/step - loss: 47.2084 - r2_keras: 0.2708 - val_loss: 46.3266 - val_r2_keras: 0.4691 - lr: 1.0000e-04\n",
            "Epoch 3/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 42.9810 - r2_keras: 0.4388\n",
            "Epoch 00003: val_loss improved from 46.32664 to 40.98577, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 180s 175ms/step - loss: 42.9810 - r2_keras: 0.4388 - val_loss: 40.9858 - val_r2_keras: 0.5179 - lr: 1.0000e-04\n",
            "Epoch 4/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 40.7265 - r2_keras: 0.4729\n",
            "Epoch 00004: val_loss improved from 40.98577 to 38.45049, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 181s 175ms/step - loss: 40.7266 - r2_keras: 0.4727 - val_loss: 38.4505 - val_r2_keras: 0.5257 - lr: 1.0000e-04\n",
            "Epoch 5/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 39.8025 - r2_keras: 0.4880\n",
            "Epoch 00005: val_loss improved from 38.45049 to 38.44824, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 173s 168ms/step - loss: 39.8027 - r2_keras: 0.4876 - val_loss: 38.4482 - val_r2_keras: 0.5265 - lr: 1.0000e-04\n",
            "Epoch 6/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 39.0668 - r2_keras: 0.4988\n",
            "Epoch 00006: val_loss improved from 38.44824 to 36.99402, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 184s 178ms/step - loss: 39.0668 - r2_keras: 0.4988 - val_loss: 36.9940 - val_r2_keras: 0.5613 - lr: 1.0000e-04\n",
            "Epoch 7/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 38.4831 - r2_keras: 0.5105\n",
            "Epoch 00007: val_loss improved from 36.99402 to 36.82673, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 183s 178ms/step - loss: 38.4831 - r2_keras: 0.5105 - val_loss: 36.8267 - val_r2_keras: 0.5563 - lr: 1.0000e-04\n",
            "Epoch 8/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 37.7107 - r2_keras: 0.5256\n",
            "Epoch 00008: val_loss did not improve from 36.82673\n",
            "1032/1032 [==============================] - 174s 169ms/step - loss: 37.7107 - r2_keras: 0.5256 - val_loss: 37.8108 - val_r2_keras: 0.4615 - lr: 1.0000e-04\n",
            "Epoch 9/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 37.1946 - r2_keras: 0.5304\n",
            "Epoch 00009: val_loss improved from 36.82673 to 35.44098, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 184s 179ms/step - loss: 37.1946 - r2_keras: 0.5304 - val_loss: 35.4410 - val_r2_keras: 0.6040 - lr: 1.0000e-04\n",
            "Epoch 10/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 36.5990 - r2_keras: 0.5406\n",
            "Epoch 00010: val_loss improved from 35.44098 to 35.01273, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 174s 169ms/step - loss: 36.5990 - r2_keras: 0.5406 - val_loss: 35.0127 - val_r2_keras: 0.5315 - lr: 1.0000e-04\n",
            "Epoch 11/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 36.2124 - r2_keras: 0.5455\n",
            "Epoch 00011: val_loss did not improve from 35.01273\n",
            "1032/1032 [==============================] - 182s 177ms/step - loss: 36.2124 - r2_keras: 0.5455 - val_loss: 36.3203 - val_r2_keras: 0.5593 - lr: 1.0000e-04\n",
            "Epoch 12/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 35.7951 - r2_keras: 0.5555\n",
            "Epoch 00012: val_loss improved from 35.01273 to 34.15784, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 182s 176ms/step - loss: 35.7945 - r2_keras: 0.5555 - val_loss: 34.1578 - val_r2_keras: 0.5797 - lr: 1.0000e-04\n",
            "Epoch 13/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 35.3525 - r2_keras: 0.5611\n",
            "Epoch 00013: val_loss improved from 34.15784 to 32.93565, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 181s 176ms/step - loss: 35.3525 - r2_keras: 0.5611 - val_loss: 32.9356 - val_r2_keras: 0.5978 - lr: 1.0000e-04\n",
            "Epoch 14/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 35.0011 - r2_keras: 0.5671\n",
            "Epoch 00014: val_loss did not improve from 32.93565\n",
            "1032/1032 [==============================] - 172s 167ms/step - loss: 35.0016 - r2_keras: 0.5666 - val_loss: 33.6512 - val_r2_keras: 0.5995 - lr: 1.0000e-04\n",
            "Epoch 15/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 34.7166 - r2_keras: 0.5684\n",
            "Epoch 00015: val_loss improved from 32.93565 to 32.79554, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 181s 176ms/step - loss: 34.7166 - r2_keras: 0.5684 - val_loss: 32.7955 - val_r2_keras: 0.5916 - lr: 1.0000e-04\n",
            "Epoch 16/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 34.4677 - r2_keras: 0.5748\n",
            "Epoch 00016: val_loss improved from 32.79554 to 32.01115, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 182s 176ms/step - loss: 34.4668 - r2_keras: 0.5751 - val_loss: 32.0112 - val_r2_keras: 0.5905 - lr: 1.0000e-04\n",
            "Epoch 17/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 34.1670 - r2_keras: 0.5762\n",
            "Epoch 00017: val_loss did not improve from 32.01115\n",
            "1032/1032 [==============================] - 181s 175ms/step - loss: 34.1674 - r2_keras: 0.5763 - val_loss: 32.3771 - val_r2_keras: 0.5834 - lr: 1.0000e-04\n",
            "Epoch 18/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 33.9047 - r2_keras: 0.5785\n",
            "Epoch 00018: val_loss did not improve from 32.01115\n",
            "1032/1032 [==============================] - 181s 175ms/step - loss: 33.9047 - r2_keras: 0.5785 - val_loss: 35.5277 - val_r2_keras: 0.6630 - lr: 1.0000e-04\n",
            "Epoch 19/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 33.6195 - r2_keras: 0.5825\n",
            "Epoch 00019: val_loss did not improve from 32.01115\n",
            "1032/1032 [==============================] - 171s 166ms/step - loss: 33.6195 - r2_keras: 0.5825 - val_loss: 32.2764 - val_r2_keras: 0.5741 - lr: 1.0000e-04\n",
            "Epoch 20/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 33.4278 - r2_keras: 0.5838\n",
            "Epoch 00020: val_loss improved from 32.01115 to 31.64728, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 180s 175ms/step - loss: 33.4271 - r2_keras: 0.5841 - val_loss: 31.6473 - val_r2_keras: 0.6168 - lr: 1.0000e-04\n",
            "Epoch 21/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 33.0068 - r2_keras: 0.5875\n",
            "Epoch 00021: val_loss improved from 31.64728 to 31.26047, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 180s 175ms/step - loss: 33.0068 - r2_keras: 0.5875 - val_loss: 31.2605 - val_r2_keras: 0.6285 - lr: 1.0000e-04\n",
            "Epoch 22/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 32.6403 - r2_keras: 0.5905\n",
            "Epoch 00022: val_loss improved from 31.26047 to 31.23413, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 172s 167ms/step - loss: 32.6403 - r2_keras: 0.5905 - val_loss: 31.2341 - val_r2_keras: 0.6037 - lr: 1.0000e-04\n",
            "Epoch 23/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 32.3288 - r2_keras: 0.5945\n",
            "Epoch 00023: val_loss did not improve from 31.23413\n",
            "1032/1032 [==============================] - 179s 174ms/step - loss: 32.3288 - r2_keras: 0.5945 - val_loss: 31.5486 - val_r2_keras: 0.6461 - lr: 1.0000e-04\n",
            "Epoch 24/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 32.2374 - r2_keras: 0.5936\n",
            "Epoch 00024: val_loss improved from 31.23413 to 30.93242, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 180s 175ms/step - loss: 32.2378 - r2_keras: 0.5935 - val_loss: 30.9324 - val_r2_keras: 0.5466 - lr: 1.0000e-04\n",
            "Epoch 25/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 32.1515 - r2_keras: 0.5915\n",
            "Epoch 00025: val_loss improved from 30.93242 to 29.59095, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 171s 166ms/step - loss: 32.1515 - r2_keras: 0.5915 - val_loss: 29.5910 - val_r2_keras: 0.6277 - lr: 1.0000e-04\n",
            "Epoch 26/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 31.7547 - r2_keras: 0.6007\n",
            "Epoch 00026: val_loss did not improve from 29.59095\n",
            "1032/1032 [==============================] - 171s 166ms/step - loss: 31.7547 - r2_keras: 0.6007 - val_loss: 30.1476 - val_r2_keras: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 27/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 31.5123 - r2_keras: 0.6001\n",
            "Epoch 00027: val_loss did not improve from 29.59095\n",
            "1032/1032 [==============================] - 172s 167ms/step - loss: 31.5123 - r2_keras: 0.6001 - val_loss: 29.6909 - val_r2_keras: 0.6088 - lr: 1.0000e-04\n",
            "Epoch 28/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 31.2729 - r2_keras: 0.6034\n",
            "Epoch 00028: val_loss improved from 29.59095 to 29.31244, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 182s 176ms/step - loss: 31.2729 - r2_keras: 0.6034 - val_loss: 29.3124 - val_r2_keras: 0.6179 - lr: 1.0000e-04\n",
            "Epoch 29/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 31.2199 - r2_keras: 0.6035\n",
            "Epoch 00029: val_loss did not improve from 29.31244\n",
            "1032/1032 [==============================] - 172s 166ms/step - loss: 31.2199 - r2_keras: 0.6035 - val_loss: 29.5404 - val_r2_keras: 0.5891 - lr: 1.0000e-04\n",
            "Epoch 30/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 31.0441 - r2_keras: 0.6044\n",
            "Epoch 00030: val_loss did not improve from 29.31244\n",
            "1032/1032 [==============================] - 180s 174ms/step - loss: 31.0441 - r2_keras: 0.6044 - val_loss: 29.5101 - val_r2_keras: 0.6190 - lr: 1.0000e-04\n",
            "Epoch 31/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 30.5606 - r2_keras: 0.6143\n",
            "Epoch 00031: val_loss improved from 29.31244 to 29.15800, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 182s 176ms/step - loss: 30.5606 - r2_keras: 0.6143 - val_loss: 29.1580 - val_r2_keras: 0.6295 - lr: 1.0000e-04\n",
            "Epoch 32/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 30.3271 - r2_keras: 0.6115\n",
            "Epoch 00032: val_loss improved from 29.15800 to 28.65246, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 182s 176ms/step - loss: 30.3271 - r2_keras: 0.6115 - val_loss: 28.6525 - val_r2_keras: 0.6627 - lr: 1.0000e-04\n",
            "Epoch 33/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 30.1650 - r2_keras: 0.6136\n",
            "Epoch 00033: val_loss improved from 28.65246 to 28.52688, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 181s 175ms/step - loss: 30.1650 - r2_keras: 0.6136 - val_loss: 28.5269 - val_r2_keras: 0.6073 - lr: 1.0000e-04\n",
            "Epoch 34/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 29.8550 - r2_keras: 0.6163\n",
            "Epoch 00034: val_loss did not improve from 28.52688\n",
            "1032/1032 [==============================] - 181s 176ms/step - loss: 29.8550 - r2_keras: 0.6163 - val_loss: 28.9065 - val_r2_keras: 0.6127 - lr: 1.0000e-04\n",
            "Epoch 35/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 29.4674 - r2_keras: 0.6232\n",
            "Epoch 00035: val_loss improved from 28.52688 to 27.56533, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 184s 178ms/step - loss: 29.4674 - r2_keras: 0.6232 - val_loss: 27.5653 - val_r2_keras: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 36/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 29.3523 - r2_keras: 0.6210\n",
            "Epoch 00036: val_loss did not improve from 27.56533\n",
            "1032/1032 [==============================] - 182s 176ms/step - loss: 29.3523 - r2_keras: 0.6210 - val_loss: 28.3798 - val_r2_keras: 0.6666 - lr: 1.0000e-04\n",
            "Epoch 37/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 29.3176 - r2_keras: 0.6232\n",
            "Epoch 00037: val_loss did not improve from 27.56533\n",
            "1032/1032 [==============================] - 172s 167ms/step - loss: 29.3176 - r2_keras: 0.6232 - val_loss: 27.8129 - val_r2_keras: 0.6146 - lr: 1.0000e-04\n",
            "Epoch 38/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 29.0564 - r2_keras: 0.6288\n",
            "Epoch 00038: val_loss improved from 27.56533 to 27.32213, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 176s 171ms/step - loss: 29.0565 - r2_keras: 0.6285 - val_loss: 27.3221 - val_r2_keras: 0.6307 - lr: 1.0000e-04\n",
            "Epoch 39/1000\n",
            "1031/1032 [============================>.] - ETA: 0s - loss: 28.7660 - r2_keras: 0.6317\n",
            "Epoch 00039: val_loss improved from 27.32213 to 26.53433, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 174s 169ms/step - loss: 28.7653 - r2_keras: 0.6317 - val_loss: 26.5343 - val_r2_keras: 0.6499 - lr: 1.0000e-04\n",
            "Epoch 40/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 28.7593 - r2_keras: 0.6369\n",
            "Epoch 00040: val_loss did not improve from 26.53433\n",
            "1032/1032 [==============================] - 172s 166ms/step - loss: 28.7593 - r2_keras: 0.6369 - val_loss: 26.8200 - val_r2_keras: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 41/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 28.7854 - r2_keras: 0.6355\n",
            "Epoch 00041: val_loss did not improve from 26.53433\n",
            "1032/1032 [==============================] - 181s 175ms/step - loss: 28.7854 - r2_keras: 0.6355 - val_loss: 29.5382 - val_r2_keras: 0.5634 - lr: 1.0000e-04\n",
            "Epoch 42/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 28.4094 - r2_keras: 0.6457\n",
            "Epoch 00042: val_loss did not improve from 26.53433\n",
            "1032/1032 [==============================] - 171s 166ms/step - loss: 28.4094 - r2_keras: 0.6457 - val_loss: 26.5694 - val_r2_keras: 0.6693 - lr: 1.0000e-04\n",
            "Epoch 43/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 28.1931 - r2_keras: 0.6517\n",
            "Epoch 00043: val_loss did not improve from 26.53433\n",
            "1032/1032 [==============================] - 181s 176ms/step - loss: 28.1931 - r2_keras: 0.6517 - val_loss: 27.6816 - val_r2_keras: 0.7054 - lr: 1.0000e-04\n",
            "Epoch 44/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 28.0018 - r2_keras: 0.6582\n",
            "Epoch 00044: val_loss did not improve from 26.53433\n",
            "1032/1032 [==============================] - 172s 167ms/step - loss: 28.0018 - r2_keras: 0.6582 - val_loss: 26.6592 - val_r2_keras: 0.6910 - lr: 1.0000e-04\n",
            "Epoch 45/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.9458 - r2_keras: 0.6564\n",
            "Epoch 00045: val_loss improved from 26.53433 to 26.31359, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 183s 178ms/step - loss: 27.9458 - r2_keras: 0.6564 - val_loss: 26.3136 - val_r2_keras: 0.7180 - lr: 1.0000e-04\n",
            "Epoch 46/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.7864 - r2_keras: 0.6587\n",
            "Epoch 00046: val_loss did not improve from 26.31359\n",
            "1032/1032 [==============================] - 185s 179ms/step - loss: 27.7864 - r2_keras: 0.6587 - val_loss: 26.6898 - val_r2_keras: 0.6863 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.6551 - r2_keras: 0.6634\n",
            "Epoch 00047: val_loss improved from 26.31359 to 25.87091, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 184s 178ms/step - loss: 27.6551 - r2_keras: 0.6634 - val_loss: 25.8709 - val_r2_keras: 0.6560 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.4865 - r2_keras: 0.6659\n",
            "Epoch 00048: val_loss did not improve from 25.87091\n",
            "1032/1032 [==============================] - 185s 179ms/step - loss: 27.4865 - r2_keras: 0.6659 - val_loss: 25.8889 - val_r2_keras: 0.6890 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.4066 - r2_keras: 0.6658\n",
            "Epoch 00049: val_loss improved from 25.87091 to 25.44208, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 177s 171ms/step - loss: 27.4066 - r2_keras: 0.6658 - val_loss: 25.4421 - val_r2_keras: 0.6981 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.4454 - r2_keras: 0.6666\n",
            "Epoch 00050: val_loss did not improve from 25.44208\n",
            "1032/1032 [==============================] - 185s 179ms/step - loss: 27.4454 - r2_keras: 0.6666 - val_loss: 25.5300 - val_r2_keras: 0.6948 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.0281 - r2_keras: 0.6736\n",
            "Epoch 00051: val_loss did not improve from 25.44208\n",
            "1032/1032 [==============================] - 187s 181ms/step - loss: 27.0281 - r2_keras: 0.6736 - val_loss: 26.5309 - val_r2_keras: 0.6308 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.1011 - r2_keras: 0.6710\n",
            "Epoch 00052: val_loss did not improve from 25.44208\n",
            "1032/1032 [==============================] - 185s 179ms/step - loss: 27.1011 - r2_keras: 0.6710 - val_loss: 25.6055 - val_r2_keras: 0.6853 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 27.0422 - r2_keras: 0.6707\n",
            "Epoch 00053: val_loss improved from 25.44208 to 24.93642, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 181s 175ms/step - loss: 27.0422 - r2_keras: 0.6707 - val_loss: 24.9364 - val_r2_keras: 0.7069 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.8495 - r2_keras: 0.6753\n",
            "Epoch 00054: val_loss improved from 24.93642 to 24.63873, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 187s 181ms/step - loss: 26.8495 - r2_keras: 0.6753 - val_loss: 24.6387 - val_r2_keras: 0.6985 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.6794 - r2_keras: 0.6756\n",
            "Epoch 00055: val_loss did not improve from 24.63873\n",
            "1032/1032 [==============================] - 184s 178ms/step - loss: 26.6794 - r2_keras: 0.6756 - val_loss: 26.5065 - val_r2_keras: 0.6924 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.6814 - r2_keras: 0.6765\n",
            "Epoch 00056: val_loss did not improve from 24.63873\n",
            "1032/1032 [==============================] - 194s 188ms/step - loss: 26.6814 - r2_keras: 0.6765 - val_loss: 26.5803 - val_r2_keras: 0.6840 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.5799 - r2_keras: 0.6790\n",
            "Epoch 00057: val_loss did not improve from 24.63873\n",
            "1032/1032 [==============================] - 200s 194ms/step - loss: 26.5799 - r2_keras: 0.6790 - val_loss: 26.2665 - val_r2_keras: 0.7362 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.5329 - r2_keras: 0.6791\n",
            "Epoch 00058: val_loss did not improve from 24.63873\n",
            "1032/1032 [==============================] - 187s 182ms/step - loss: 26.5329 - r2_keras: 0.6791 - val_loss: 26.1165 - val_r2_keras: 0.6933 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.4490 - r2_keras: 0.6824\n",
            "Epoch 00059: val_loss did not improve from 24.63873\n",
            "1032/1032 [==============================] - 191s 185ms/step - loss: 26.4490 - r2_keras: 0.6824 - val_loss: 24.7109 - val_r2_keras: 0.6924 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.2641 - r2_keras: 0.6835\n",
            "Epoch 00060: val_loss did not improve from 24.63873\n",
            "1032/1032 [==============================] - 190s 184ms/step - loss: 26.2641 - r2_keras: 0.6835 - val_loss: 25.2710 - val_r2_keras: 0.6630 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.1038 - r2_keras: 0.6871\n",
            "Epoch 00061: val_loss improved from 24.63873 to 24.12844, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 191s 185ms/step - loss: 26.1038 - r2_keras: 0.6871 - val_loss: 24.1284 - val_r2_keras: 0.7135 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.0805 - r2_keras: 0.6899\n",
            "Epoch 00062: val_loss did not improve from 24.12844\n",
            "1032/1032 [==============================] - 190s 184ms/step - loss: 26.0805 - r2_keras: 0.6899 - val_loss: 24.6153 - val_r2_keras: 0.7172 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.1407 - r2_keras: 0.6848\n",
            "Epoch 00063: val_loss did not improve from 24.12844\n",
            "1032/1032 [==============================] - 180s 174ms/step - loss: 26.1407 - r2_keras: 0.6848 - val_loss: 24.7366 - val_r2_keras: 0.6924 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.0226 - r2_keras: 0.6887\n",
            "Epoch 00064: val_loss improved from 24.12844 to 23.96056, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 189s 183ms/step - loss: 26.0226 - r2_keras: 0.6887 - val_loss: 23.9606 - val_r2_keras: 0.7305 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 26.0234 - r2_keras: 0.6881\n",
            "Epoch 00065: val_loss did not improve from 23.96056\n",
            "1032/1032 [==============================] - 192s 186ms/step - loss: 26.0234 - r2_keras: 0.6881 - val_loss: 24.1473 - val_r2_keras: 0.7163 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.8550 - r2_keras: 0.6872\n",
            "Epoch 00066: val_loss improved from 23.96056 to 23.90447, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 184s 179ms/step - loss: 25.8550 - r2_keras: 0.6872 - val_loss: 23.9045 - val_r2_keras: 0.7052 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.9876 - r2_keras: 0.6807\n",
            "Epoch 00067: val_loss did not improve from 23.90447\n",
            "1032/1032 [==============================] - 194s 188ms/step - loss: 25.9876 - r2_keras: 0.6807 - val_loss: 24.5573 - val_r2_keras: 0.6955 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.5651 - r2_keras: 0.6962\n",
            "Epoch 00068: val_loss improved from 23.90447 to 23.87098, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 192s 186ms/step - loss: 25.5651 - r2_keras: 0.6962 - val_loss: 23.8710 - val_r2_keras: 0.7037 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.6977 - r2_keras: 0.6901\n",
            "Epoch 00069: val_loss did not improve from 23.87098\n",
            "1032/1032 [==============================] - 192s 186ms/step - loss: 25.6977 - r2_keras: 0.6901 - val_loss: 24.6893 - val_r2_keras: 0.7378 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.5304 - r2_keras: 0.6928\n",
            "Epoch 00070: val_loss did not improve from 23.87098\n",
            "1032/1032 [==============================] - 183s 178ms/step - loss: 25.5304 - r2_keras: 0.6928 - val_loss: 25.2972 - val_r2_keras: 0.6688 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.6807 - r2_keras: 0.6881\n",
            "Epoch 00071: val_loss improved from 23.87098 to 23.66781, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 180s 174ms/step - loss: 25.6807 - r2_keras: 0.6881 - val_loss: 23.6678 - val_r2_keras: 0.7197 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.3494 - r2_keras: 0.6977\n",
            "Epoch 00072: val_loss improved from 23.66781 to 23.52880, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 180s 175ms/step - loss: 25.3494 - r2_keras: 0.6977 - val_loss: 23.5288 - val_r2_keras: 0.7139 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.3855 - r2_keras: 0.6974\n",
            "Epoch 00073: val_loss did not improve from 23.52880\n",
            "1032/1032 [==============================] - 180s 175ms/step - loss: 25.3855 - r2_keras: 0.6974 - val_loss: 25.3036 - val_r2_keras: 0.6769 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.1476 - r2_keras: 0.7019\n",
            "Epoch 00074: val_loss improved from 23.52880 to 23.26531, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/weights_LSTM_10.h5\n",
            "1032/1032 [==============================] - 193s 187ms/step - loss: 25.1476 - r2_keras: 0.7019 - val_loss: 23.2653 - val_r2_keras: 0.7353 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.1314 - r2_keras: 0.7025\n",
            "Epoch 00075: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 188s 183ms/step - loss: 25.1314 - r2_keras: 0.7025 - val_loss: 28.3312 - val_r2_keras: 0.5918 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.1837 - r2_keras: 0.6975\n",
            "Epoch 00076: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 188s 182ms/step - loss: 25.1837 - r2_keras: 0.6975 - val_loss: 23.6190 - val_r2_keras: 0.7206 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.2051 - r2_keras: 0.6996\n",
            "Epoch 00077: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 192s 186ms/step - loss: 25.2051 - r2_keras: 0.6996 - val_loss: 24.9032 - val_r2_keras: 0.6707 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.0517 - r2_keras: 0.7020\n",
            "Epoch 00078: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 184s 178ms/step - loss: 25.0517 - r2_keras: 0.7020 - val_loss: 24.5182 - val_r2_keras: 0.6705 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.1654 - r2_keras: 0.6989\n",
            "Epoch 00079: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 189s 183ms/step - loss: 25.1654 - r2_keras: 0.6989 - val_loss: 23.5011 - val_r2_keras: 0.7140 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 24.8559 - r2_keras: 0.7059\n",
            "Epoch 00080: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 188s 183ms/step - loss: 24.8559 - r2_keras: 0.7059 - val_loss: 23.3171 - val_r2_keras: 0.7326 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 25.0321 - r2_keras: 0.7017\n",
            "Epoch 00081: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 188s 182ms/step - loss: 25.0321 - r2_keras: 0.7017 - val_loss: 23.4904 - val_r2_keras: 0.7287 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 24.9602 - r2_keras: 0.6991\n",
            "Epoch 00082: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 179s 174ms/step - loss: 24.9602 - r2_keras: 0.6991 - val_loss: 23.6985 - val_r2_keras: 0.7149 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 24.7506 - r2_keras: 0.7060\n",
            "Epoch 00083: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 187s 181ms/step - loss: 24.7506 - r2_keras: 0.7060 - val_loss: 23.6432 - val_r2_keras: 0.6824 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 24.6391 - r2_keras: 0.7081\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 23.26531\n",
            "1032/1032 [==============================] - 189s 183ms/step - loss: 24.6391 - r2_keras: 0.7081 - val_loss: 23.5809 - val_r2_keras: 0.7097 - lr: 1.0000e-04\n",
            "Epoch 00084: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_acc_loss(history_1,  f\"LSTM-v0_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}\")\n",
        "\n",
        "print('\\n\\n')\n",
        "score = model_1.evaluate(X_test, y_test,verbose=1)\n",
        "print(f'{score}')\n",
        "\n",
        "out_file = open(f'{SAVE_PATH}/statistics.txt', \"a\")\n",
        "out_file.write(f\"LSTM-v0 \\t {score}\")\n",
        "out_file.close()"
      ],
      "metadata": {
        "id": "3DDsIfjyOo71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "d1d16f16-f1c9-4b0a-be01-ad058886a134"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3jUVdbA8e+ZyaT3hABJCIQeeokICkpTQRSwIKjY1pXVdVddddey7xZ3davr4tq72EUEUVFUEBQLSJEqSIcESCCBhJCezH3/uJOQQICAGSbJnM/z5Enm1+bOPJMz93fLuWKMQSmllP9w+LoASimlTi8N/Eop5Wc08CullJ/RwK+UUn5GA79SSvkZDfxKKeVnNPArdRwi8rKIPFjPY7eLyMifeh2lvE0Dv1JK+RkN/Eop5Wc08Ksmz9PE8lsRWS0ihSLygoi0FJGPRaRAROaJSEyN48eKyDoRyRORhSKSVmNfXxFZ4TnvbSD4iOe6SERWes79RkR6nWKZbxKRzSKyX0TeF5FEz3YRkf+KyF4ROSgia0Skh2ffhSLyg6dsu0Tk7lN6w5Tf08CvmovLgPOAzsDFwMfA/UAL7Of8NgAR6Qy8Cdzh2fcR8IGIBIpIIPAe8CoQC7zjuS6ec/sCLwK/AOKAZ4D3RSToZAoqIsOBvwNXAK2BHcBbnt3nA+d4XkeU55hcz74XgF8YYyKAHsDnJ/O8SlXRwK+ai8eMMdnGmF3AImCJMeZ7Y0wJMAvo6zluIjDHGPOZMaYceBgIAc4CBgIuYKoxptwYMwNYWuM5pgDPGGOWGGMqjTHTgFLPeSfjauBFY8wKY0wpcB8wSETaAeVABNAVEGPMemPMHs955UA3EYk0xhwwxqw4yedVCtDAr5qP7Bp/F9fxONzzdyK2hg2AMcYNZABJnn27TO3MhTtq/N0WuMvTzJMnInlAG895J+PIMhzC1uqTjDGfA48DTwB7ReRZEYn0HHoZcCGwQ0S+EJFBJ/m8SgEa+JX/2Y0N4IBtU8cG713AHiDJs61KSo2/M4CHjDHRNX5CjTFv/sQyhGGbjnYBGGP+Z4zpD3TDNvn81rN9qTFmHJCAbZKafpLPqxSggV/5n+nAGBEZISIu4C5sc803wLdABXCbiLhE5FJgQI1znwNuFpEzPZ2wYSIyRkQiTrIMbwI3iEgfT//A37BNU9tF5AzP9V1AIVACuD19EFeLSJSnieog4P4J74PyYxr4lV8xxvwITAYeA3KwHcEXG2PKjDFlwKXA9cB+bH/AzBrnLgNuwjbFHAA2e4492TLMA/4AvIu9y+gATPLsjsR+wRzANgflAv/27LsG2C4iB4GbsX0FSp000YVYlFLKv2iNXyml/IwGfqWU8jMa+JVSys9o4FdKKT8T4OsC1Ed8fLxp166dr4uhlFJNyvLly3OMMS2O3N4kAn+7du1YtmyZr4uhlFJNiojsqGu7NvUopZSf0cCvlFJ+RgO/Ukr5mSbRxl+X8vJyMjMzKSkp8XVRmoXg4GCSk5NxuVy+LopSysuabODPzMwkIiKCdu3aUTuZojpZxhhyc3PJzMwkNTXV18VRSnlZk23qKSkpIS4uToN+AxAR4uLi9O5JKT/RZAM/oEG/Ael7qZT/aNKB/0QOFJWRe6jU18VQSqlGpVkH/vyicvYXlnnl2nl5eTz55JMnfd6FF15IXl6eF0qklFL106wDvwi4vbTcwLECf0VFxXHP++ijj4iOjvZOoZRSqh6a7Kie+nCI4PbSQjP33nsvW7ZsoU+fPrhcLoKDg4mJiWHDhg1s3LiR8ePHk5GRQUlJCbfffjtTpkwBDqefOHToEKNHj2bw4MF88803JCUlMXv2bEJCQrxSXqWUqtIsAv8DH6zjh90Hj9peVuGmwu0mNPDkX2a3xEj+dHH3Y+7/xz/+wdq1a1m5ciULFy5kzJgxrF27tno45IsvvkhsbCzFxcWcccYZXHbZZcTFxdW6xqZNm3jzzTd57rnnuOKKK3j33XeZPHnySZdVKaVORrMI/MckcLoWlhwwYECtMfD/+9//mDVrFgAZGRls2rTpqMCfmppKnz59AOjfvz/bt28/TaVVSvmzZhH4j1Uzzz5YQvbBEnomRXl9uGJYWFj13wsXLmTevHl8++23hIaGMnTo0DrHyAcFBVX/7XQ6KS4u9moZlVIKmnnnrsMT7L3Rzh8REUFBQUGd+/Lz84mJiSE0NJQNGzawePHiBn9+pZQ6Vc2ixn8sDk8l323A2cDXjouL4+yzz6ZHjx6EhITQsmXL6n2jRo3i6aefJi0tjS5dujBw4MAGfnallDp1Yrw06qUhpaenmyMXYlm/fj1paWnHPe9AYRkZB4ro0jKCIFdDh/7mpz7vqVKq6RCR5caY9CO3N/OmHvvbW2P5lVKqKWregd/hvTZ+pZRqqpp34Pdi565SSjVVzTrwizb1KKXUUZp14K+q8TeFDmyllDpd/CLwa1OPUkod1swDv/3tdvu2HADh4eEA7N69m8svv7zOY4YOHcqRw1aPNHXqVIqKiqofa5pnpdTJauaBv/HV+BMTE5kxY8Ypn39k4Nc0z0qpk9WsA78ICN7p3L333nt54oknqh//+c9/5sEHH2TEiBH069ePnj17Mnv27KPO2759Oz169ACguLiYSZMmkZaWxiWXXFIrV88tt9xCeno63bt3509/+hNgE7/t3r2bYcOGMWzYMMCmec7JyQHgkUceoUePHvTo0YOpU6dWP19aWho33XQT3bt35/zzz9ecQEr5ueaRsuHjeyFrzVGbBWhfVkGAQyDgJGfutuoJo/9xzN0TJ07kjjvu4NZbbwVg+vTpfPLJJ9x2221ERkaSk5PDwIEDGTt27DETxD311FOEhoayfv16Vq9eTb9+/ar3PfTQQ8TGxlJZWcmIESNYvXo1t912G4888ggLFiwgPj6+1rWWL1/OSy+9xJIlSzDGcOaZZ3LuuecSExOj6Z+VUrU06xq/N/Xt25e9e/eye/duVq1aRUxMDK1ateL++++nV69ejBw5kl27dpGdnX3Ma3z55ZfVAbhXr1706tWret/06dPp168fffv2Zd26dfzwww/HLc9XX33FJZdcQlhYGOHh4Vx66aUsWrQI0PTPSqnamkeN/zg184ysg4QGBpASG9rgTzthwgRmzJhBVlYWEydO5PXXX2ffvn0sX74cl8tFu3bt6kzHfCLbtm3j4YcfZunSpcTExHD99def0nWqaPpnpVRNzb7G7xDB7aUZXBMnTuStt95ixowZTJgwgfz8fBISEnC5XCxYsIAdO3Yc9/xzzjmHN954A4C1a9eyevVqAA4ePEhYWBhRUVFkZ2fz8ccfV59zrHTQQ4YM4b333qOoqIjCwkJmzZrFkCFDGvDVKqWai+ZR4z8Ob6672717dwoKCkhKSqJ169ZcffXVXHzxxfTs2ZP09HS6du163PNvueUWbrjhBtLS0khLS6N///4A9O7dm759+9K1a1fatGnD2WefXX3OlClTGDVqFImJiSxYsKB6e79+/bj++usZMGAAAD//+c/p27evNusopY7SrNMyA2zddwi3gY4J4d4qXrOhaZmVal78Mi0z2Bp/U/hyU0qp08UvAr8maVNKqcO8GvhFJFpEZojIBhFZLyKDRCRWRD4TkU2e3zGnev361OQd0rhm7jZWeleklP/wdo3/UWCuMaYr0BtYD9wLzDfGdALmex6ftODgYHJzc08YsBwO73XuNhfGGHJzcwkODvZ1UZRSp4HXRvWISBRwDnA9gDGmDCgTkXHAUM9h04CFwD0ne/3k5GQyMzPZt2/fcY/LLy7nUGkFjvyQk30KvxIcHExycrKvi6GUOg28OZwzFdgHvCQivYHlwO1AS2PMHs8xWUDLuk4WkSnAFICUlJSj9rtcLlJTU09YiMfmb+I/n21k00OjcTmbfZeGUkqdkDcjYQDQD3jKGNMXKOSIZh1j22nqbIcxxjxrjEk3xqS3aNHilAsREmhz9BSVVZ7yNZRSqjnxZuDPBDKNMUs8j2dgvwiyRaQ1gOf3Xi+WoTrwl5Rr4FdKKfBi4DfGZAEZItLFs2kE8APwPnCdZ9t1wNG5ixtQqNb4lVKqFm+nbPg18LqIBAJbgRuwXzbTReRGYAdwhTcLEOKqCvwV3nwapZRqMrwa+I0xK4Gjpgtja/+nRUigfYna1KOUUlazH+aiTT1KKVVbsw/8h5t6NPArpRT4Q+D31PiLNfArpRTgB4G/qqmnWNv4lVIK8IfA77Kdu9rUo5RSVrMP/IebenQ4p1JKgR8EfpdTcDpEm3qUUsqj2Qd+ESHU5dSmHqWU8mj2gR9sc4+O6lFKKctvAr/W+JVSyvKPwO9yahu/Ukp5+EXgD9WmHqWUquYngT9As3MqpZSHXwT+YB3Vo5RS1fwi8IcGOjUts1JKefhN4Ncav1JKWX4R+HUcv1JKHeYfgV+HcyqlVDW/CPyhgU4q3IayCrevi6KUUj7nF4G/at1dbe5RSil/CfxVyy+W61h+pZTyi8AfqssvKqVUNb8I/FWLseiQTqWU8pPAr+vuKqXUYX4R+Kva+LWpRyml/CXwa1OPUkpV84vAH1o1nFNH9SillL8Efq3xK6VUFb8I/MHaxq+UUtX8IvDrOH6llDrMLwK/y+nA5RSKdDinUkr5R+AH29yjNX6llPKjwK8LriullOVHgT9Am3qUUormHvi3LIAf3gc8i7GU6Th+pZQK8HUBvGrJM3BgO3Qba5df1Bq/Uko18xp/QhrkboKKMl1wXSmlPLxa4xeR7UABUAlUGGPSRSQWeBtoB2wHrjDGHPBKARK6gbsC9m8hxOVkX0GpV55GKaWaktNR4x9mjOljjEn3PL4XmG+M6QTM9zz2joSu9vfeHwjRGr9SSgG+aeoZB0zz/D0NGO+1Z4rrBOKEvRvscE5t41dKKa8HfgN8KiLLRWSKZ1tLY8wez99ZQMu6ThSRKSKyTESW7du379Se3RUMcR1sjd8VoOP4lVIK74/qGWyM2SUiCcBnIrKh5k5jjBERU9eJxphngWcB0tPT6zymXlp0hex1hHZxUlRWgTEGETnlyymlVFPn1Rq/MWaX5/deYBYwAMgWkdYAnt97vVkGErrBgW2EO8txGyirdHv16ZRSqrHzWuAXkTARiaj6GzgfWAu8D1znOew6YLa3ygDYDl7jplVZBqAZOpVSyptNPS2BWZ5mlQDgDWPMXBFZCkwXkRuBHcAVXiyDrfEDrUq3Au0oKqskOtSrz6iUUo2a1wK/MWYr0LuO7bnACG8971Fi24MzkLiiw4FfKaX8WfOeuQvgdEFcJ6IPbQagRId0KqX8XPMP/AAJaUQc3ATourtKKeU3gT+4cBdhFFOkGTqVUn7ObwI/QCfZpU09Sim/51eBv7MjQ5t6lFJ+zz8Cf3Q7TEAInSVTA79Syu/5R+B3OHDHd6azZFJYqm38Sin/5h+BH3C07EZXZybbcgp9XRSllPIpvwn8kpBGAgfYuWuXr4uilFI+5TeBvyp1A3vXU6GJ2pRSfsyPAr8d2dPe7GTLPm3uUUr5L/8J/JFJuANCaS97+GFPvq9Lo5RSPlOvwC8it4tIpFgviMgKETnf24VrUCJIfEc6OLL4YfdBX5dGKaV8pr41/p8ZYw5ic+rHANcA//BaqbxE4jrSOSCbdRr4lVJ+rL6Bv2qtwguBV40x62psazriOtLSnc2m3bkYc+qrOSqlVFNW38C/XEQ+xQb+TzwrazW9oTHxnXDgJrJkF3vyS3xdGqWU8on6LsRyI9AH2GqMKRKRWOAG7xXLS+I6ANBe9rBu90ESo0N8XCCllDr96lvjHwT8aIzJE5HJwP8BTW9oTKwn8Dv2aAevUspv1TfwPwUUiUhv4C5gC/CK10rlLSHRENaCXsE5OqRTKeW36hv4K4ztDR0HPG6MeQKI8F6xvCiuI11cOrJHKeW/6hv4C0TkPuwwzjki4gBc3iuWF8V1JLFiF5kHiskvLvd1aZRS6rSrb+CfCJRix/NnAcnAv71WKm+K60hoeS4RFLF+j9b6lVL+p16B3xPsXweiROQioMQY0/Ta+AHiOgLQTnQGr1LKP9U3ZcMVwHfABOAKYImIXO7NgnmNJ/D3Dtmn7fxKKb9U33H8vwfOMMbsBRCRFsA8YIa3CuY1sakgDtLDc3lGm3qUUn6ovm38jqqg75F7Euc2LgFBEJ1CZ1c2m/cWUFbR9CYgK6XUT1Hf4D1XRD4RketF5HpgDvCR94rlZXEdSarcTXmlYcm2XF+XRimlTqv6du7+FngW6OX5edYYc483C+ZVcR2JLNpBRJCT91fu9nVplFLqtKp3c40x5l1jzJ2en1neLJTXxXVEyg4xoYuLuWuzKCmv9HWJlFLqtDlu4BeRAhE5WMdPgYg03Z5Rz8ieS1KKKSitYMGGvSc4QSmlmo/jBn5jTIQxJrKOnwhjTOTpKmSD8wT+7kH7aBERxHsrd/m4QEopdfo0zZE5P1VkEgSE4Ni/mYt7JbJgwz5N36CU8hv+GfgdDpubP3cz4/okUlbpZu7aPb4ulVJKnRb+GfihOvD3So6iXVwos3V0j1LKT/hx4O8IB7Yj7grG9Uni2625ZOlyjEopP+C/gT++C7grIHsd4/okYgx8uFpr/Uqp5s9/A3+H4SAO+PEj2rcIp1dyFC99vZ3cQ6W+LplSSnmV1wO/iDhF5HsR+dDzOFVElojIZhF5W0QCvV2GOoW3gDYDYcMcAB4Y252cQ6VMeXW5TuhSSjVrp6PGfzuwvsbjfwL/NcZ0BA4AN56GMtQt7SLIXgv7t9E3JYapE/uwYucB7npnFW638VmxlFLKm7wa+EUkGRgDPO95LMBwDqdzngaM92YZjqvrGPvbU+sf3bM1943uypzVe/j3pz/6rFhKKeVN3q7xTwV+B1TlPo4D8owxFZ7HmUBSXSeKyBQRWSYiy/bt2+ed0sW0g5Y9YcOH1ZtuGtKeq89M4amFW3h+0VbvPK9SSvmQ1wK/Z4nGvcaY5adyvjHmWWNMujEmvUWLFg1cuhq6joGdi+GQ/XIRER4Y253RPVrx4Jz1/OfTHzFGm32UUs2HN2v8ZwNjRWQ78Ba2iedRIFpEqlb+SgZ8mygn7SLAwI+HlxcIcDp4/Kp+TDqjDY99vpk/zF5Lpbb5K6WaCa8FfmPMfcaYZGNMO2AS8Lkx5mpgAVC1Xu91wGxvlaFeWvaA6JTqdv4qTofw90t7cvO5HXht8U5ue+t7ist0tI9SqunzxTj+e4A7RWQzts3/BR+U4TAR6HoxbF0ApQVH7BLuHd2V+y+0Hb7jnviKH7MKjnEhpZRqGk5L4DfGLDTGXOT5e6sxZoAxpqMxZoIxxvczprqOgcoy2Dyvzt1TzunAqzcOYH9hOWMf/4rXl+zQdn+lVJMlTSGApaenm2XLlnnvCdyV8HAnCI6Glt3ttoAgGHI3JHStPmxfQSl3Tl/Jok05jOuTyMMTeuNy+u/kZ6VU4yYiy40x6Udu16gF4HDC4N+AMxByNtqfHz+G926BGl+MLSKCmHbDAO4+vzOzV+7ml6+voLRC2/2VUk2L1viPZeUbNvBf/iL0uOyo3a98u50/zl7H0C4teHpyf4JdztNbPqWUOgGt8Z+sXhPtiJ95D0DF0d0Q1w5qxz8u7cmSjZksnHoDRRmrfFBIpZQ6eRr4j8XhhPMegLwdsLTugUeTzmjDp+3fYVThbBa/fC/fbM45zYVUSqmTp4H/eDqMgPZD4ct/QXHe0fu/+R9tdn1EaWhrzqpcxo3Pf8E9M1br+r1KqUZNA//xiMB5f7FB/6tHau/bNA8++xN0G0/QhOcIpoy/99jDjBWZnPfIF1r7V0o1Whr4T6R1b9ve/+0T8OJo+OT3sOIVmPEzO/Rz/JPQ9iwIb8l41xJm33o2EcEBXP3CEv772UZN9aCUanQ08NfHqL/DgF/YpRq/ew7e/7XtA5j0BgSG2b+7jYNNn9Ij3skHvx7MpX2TeXT+JiY/v4S9B3UtX6VU46HDOU9WZTlkr4OQGIhpe3j7jm/gpdFw2QvQ06YiemdZBn+cvQ6HwOSBbblxSCoJEcE+KrhSyt/ocM6G4nRBYp/aQR/sMo4RrWHdrOpNE9LbMOe2wYzs1pLnFm1l1D8/Yut/hrN/5RyUUspXNPA3FIcDuo2HTZ9BycHqze1bhPPopL7Mv2so/205l/YFy9k48yH+9tF69heW+bDASil/pYG/IXW/BCpLYePco3alVm7n3P0zqAyOZaBjHR8tWsI5/1rA1HkbKSytqONiSinlHRr4G1LyGRCZVKu5BwC3Gz68E0KicV47E4D3huxicMd4ps7bxNCHF/LWdzsbbgSQMZC3s2GupZRqdjTwN6Sq5p7N82DtzMMJ3la9CRmL7ZyAxL7QdjDxW2by9OR+vHvLWaTEhnLvzDWMfvRLPl2XhfunfgGseQce7QP7t/3016SUanY08De0gTdDXEeYcQM8NwzWfwCf/cF2/va+yh7TexLkbobMZfRvG8OMmwfx1NX9KK1wM+XV5Yx45Ate+Xb7qTcBbfoMTCVs+6LBXpZSqvnQwN/QolPg5q9g/FNQmANvT7Yzf8f8x94RgB3zHxBi7wSwK32N7tmaeXeey/+u7EtkiIs/zl7HoL/P54+z17J8x4H6L/xiDGxfZP/e8Y0XXqBSqqnTcfzeVF4CK6ZBUCT0ubL2vnd/bmvmd2+0i77UYIxhxc48Xv5mO5+uy6K0wk3buFDG9k5kVI9WdGsdiYjU/Zw5m+Hx/hAQDKHx8Ju1NvWEUsrvHGscf4AvCuM3XMFw5i/q3td7km2L3zjX3gHUICL0bxtD/7YxFJSU88m6bN77fhdPLNjMY59vJik6hPO7t+TCnq1JbxtT+0tg+5f2d/8bYMlTNrtoTDvvvD6lVJOkgd9X2g+D8Faw6q2jAn9NEcEuLu+fzOX9k8k5VMr89dl8ui6b15fs5KWvt9M2LpTL+yVzaf9kkqJDYPtXdiJZv2tt4N/+tQZ+pVQtGvh9xeGEXlfA4ift0MvolBOeEh8exMQzUph4RgqHSiuYuzaLGcsz+M9nG3lk3kbSU6KZdmAh0n4oIS26Qkgs7Pga+l7t9ZejlGo6tHPXlwZMAWcQfHBHrbV96yM8KIDL+yfz1pRBLPrdMO4Y0Zmowu2EluXy5zWxXPbMYnZE9KFy21deKrxSqqnSwO9L0W1g5J9hy/zqET7VKkrhy4dtQrgTaBMbyu0jO/H8OUUAdD9rDIdKKpi2Kwln/g7uev4j3lmWQcb+ovqPDlJKNVva1ONrZ/wc1s2EufdCh+EQ0QpK8uGtq+2wzMVPwc/mQnynE19r+yKITObaC4dy7Rhh65oAePdVwrMW89sZNuC3jgpmQGosE9PbcFbHeC+/OKVUY6Q1fl9zOGDsY3bo55y74OAeeOlC2PktjHzADsV8ZTzkZRz/OsbYjt3UIdXDN9t3PxOCovhzrzw+ueMc/jquO/3bxvDVphyuen4Jk59fwqqMOpaUVEo1a1rjbwziO8Gw+2Den21nbGU5XP2OvQPoMBxevgheHQ83zIXwFnVfY+96KMqFdkMOb3M4oe0gZMc3dBkbQZdWEVwzqB0l5ZW8tngHTy7cwrgnvmZU91b8clgHeiVHn5aXq5TyLa3xNxaDfg2J/cARANfPsQEfoHUvuOptyN8Fr10KxQfqPr9qtm67wbW3tz0LcjdBQXb1pmCXk58Pac8Xvx3KHSM78fXmHMY+/jVXPruYhT/u1X4ApZo5DfyNhdMT8G9baRd6qantIJj4GuzbAK+Mg6L9R5+/7Us7JPTIBWLaer4Idnx91CkRwS7uGNmZb+4bzu8vTGNbTiHXv7SU8//7Jc8v2qrrBSjVTGnKhqZk02e20ze+M1w7G8LibNv+ti9g+rXQ9WIY/0Ttcyor4J9t7UzhMf857uXLKty8v2o3ry/Zwfc783A5hfO7taJf2xgSo4JJjA6hdXQw8WFBOByaBkKpxu5YKRs08Dc1m+fDW1dBbAc461ew5GnYswrCEuDKtyC5/9HnvDHJfjmMfax6PeAT+TGrgLeXZjDr+0wOFJXX2hfgEFpGBtMqKpg+baK5aUh7WkXpWsJKNTYa+JuTrQttMK8otimgz7oNek20uYHqUpAF06+zawIM+pUdLeSsX7++MYa8onJ25xezO6+EPfnFZOWXkJVfwu78YpZtP4DDIVx5RhtuGdpRvwCUakQ08Dc3e1bZDtuOIw+nez6eijL49P/gu2fsyJ/xT9kJZD9Rxv4inliwmRnLM3GIMLxrAiO7tWRYlxbEhQed+AJKKa/RwK+sVW/DB7eDu8Kmih58J8SmHn3cgR3w/auw4SPoMhqG3nfcu4SM/UW88NU25q7NIutgCQ6BfikxjEhryci0BDomhB87lbRSyis08KvD8jLg60dhxSv2C6DrhRCRaNcFcIVA5jLY8rk9tlUPyFpj7xIufxHCE457aWMM63Yf5LMfspm3Ppt1uw8CkBIbSt+UaKJDXESFuIgKDaRzy3B6t4kmMtjl7VeslF/SwK+OVpAF3zxmF4cvK4SKEvsTmQx9J9usntEp8P3rMOdOCImBCS9DysB6P0VWfgnzN2Qzf/1eNu0tIL+onILSiuqcdCLQKSGcM1PjuGVoBxKjQ7zzWpXyQxr4Vf3UjMg17Vlth4zmZ8KUBdCq5yk/RaXbkF9czrrd+azYkceKnQdYvDUXp0O4fUQnfjY4FZdTp5go9VNp4Fc/XWEuPJ4OLbrADR836JKOGfuLeOCDdcxbv5dOCeH89oIunNO5BcEuZ4M9h1L+5liB32vVKhEJFpHvRGSViKwTkQc821NFZImIbBaRt0Uk0FtlUA0sLA5G/skmkFvzToNeuk1sKM9fdwbPX5tOcXklU15dTp+/fMrPXl7Kq4t3sDG7gEp346+kKNUUeK3GL3YIR5gx5pCIuICvgNuBO4GZxpi3RORpYJUx5qnjXUtr/I2IuxKeHwEHd8OvlkFwpN1eWW6XkUxOh4S0n/QUpRWVLNm6n8837OXzDXvZud+uMxDictIjKZI+baIZ1yeJHklRP/XVKNWs+bSpR0RCsYH/FmAO0MoYUyEig4A/G2MuON75Gvgbmczl8PxwOOvXcBPRjSYAABjuSURBVP6DkLMZZt4Eu1eAOCH9Bhh6v71D+ImMMWzLKWRVZh6rM/NZk5nP6sx8yird9EiKZGJ6G8b2SSIqREcGKXUknwR+EXECy4GOwBPAv4HFxpiOnv1tgI+NMT3qOHcKMAUgJSWl/44dO7xWTnUKZv/Krho25C74+n921vAFf4NdK2DZixAUDufeA+k/s0NEG1B+UTnvrdzFW0szWL/nIOFBAVw7qC03Dk7VSWNK1eDrGn80MAv4A/ByfQJ/TVrjb4QKc+Cxfna1sA7DYdyTENna7tu7Hj65384FCEuAQb+E9Btts1BBFmyeB1u/gMpScIVCQDCExUPvKyGuQ72LYIxhza58nvlyKx+t2UNwgJOrz0xheFoC7eLCaBUZ3DDJ5IyBz/8K3S+18xqUaiJ8PqpHRP4IFAP3oE09zcPWL2xbf+9JR4/wMcamgl70iF1TOCjKzgnIXmP3h7e08wLKi6C82KaaNm7oPMp+UbQbclKjhjbvPcSTCzcze+Xu6k7goAAHyTEhhAe7CHU5CQ100jYujFE9WtG/bQzO+n4p7FkNzwyBPpOPzn6qVCN22gO/iLQAyo0xeSISAnwK/BO4Dni3RufuamPMk8e7lgb+Jm7393amcGGOvTvodB607FE7sBdkw7IXYOnzdiWx5DPgoqknXcPeV1DKxuwCtuUUsj2nkMwDxRSVV1JcVkFhaSWb9x2irMJNi4ggRnVvxdg+iaS3jTl+Ookv/w2fPwiRSfCbdQ06jFUpb/JF4O8FTAOc2GGj040xfxGR9sBbQCzwPTDZGFN6vGtp4Pcj5cV2dNDnD0JJnu1APveeuvsJ9m+Fb5+A0Hi7dGU9HCqtYMGGvXy8dg+fb9hLSbmbNrEhXNIniVE9WhMRHIDDITjETjQrrXDTesZYQrOX2wv8aln9Fr5XqhHweVPPT6GB3w8V7bfZRFe+DjGpNu10fCc7ecy4baqJte/avwGu/wjanX1ST1FYWsEn67KYuWIXX2/Joa5/hVgOsizoFma5B3OZcxGLOv6OPpf/jgjNL6SaAA38qmna+gV88nvIXgvU+KwGhtsRQ+k/g2ljISgCfvFl7Qyi5cWQsQTanXPC1NVZ+SV8uzWH8kqDMQZjbItOxz1z6L/iXhYNe4cuX/6aVWVJ3Om8h6vOTOH8bq3onRxFgKaXaJ7KiiAw1Nel+Ek08KumrbwE9m+BnI12wflu4yE01u5b/yG8fTWM+icMvNlzfDG8cYVdizj1XLjkaYhMPPnnfecG2P4V3PUjzPkNlatncHvbmcxZZ+8QIoIDOKtDHIM7xnNGaiydEyJ0WcrmYMvndrGj276HqCRfl+aUHSvw128ZJqV8zRUMLbvbnyN1HQMdRsCCh6DHpRAUaZen3LbI3hGsegueOssuPZl2cf2fs7LCjkjqerG9Y2g/DOfyl3n8HPjrJefx9ZYcvtqUw6JNOXyyLhuAqBAX6W1jaBMbSlSIi+hQF/HhQaS1jqR9fJh+KTQVGd/Z4ca7m3bgPxYN/KrpE4HR/4QnB9l+geI8W2Mb+zj0uwYG/hLe/Tm8PdkOyTz/r4fvFo4nY4mdp9D5fPs49RxAYOsCYlLO5KJeiVzUKxFTWU5GTgHfZRaxdNt+lu3Yz9Lt+zlYUlHrcmGBTronRdGtdSSdWobTKSGCTgnhxIRpuqpGJ2ej/b13PaRd5NuyeIEGftU8xHeCQbfC11Pt44um2qBfte/Gz2Dh3+2w0o0fw3l/hT5XHX9o5qZPwOGC9sPs49BYSOwLWxbA0HvttsoKZNpYUg5lk3LTfC7vn1x9ekWlm4KSCrIOlrB2Vz5rd+WzZlc+05dlUFRWWX1cUnQIvdtE0adNND0So0iMDiEhMojQwMP/nm7PCKOQQM1Welrs8wT+fet9Ww4v0cCvmo9zfmvXIu42zuYLqikg0GYW7XGZXVRm9i/h+9dg/JN1Lz0JsPFTaDvocCI6gPZD7ZdHyUG7/Yt/ws5vQBww62aY9GZ1R3KA00FMWCAxYYGktY5kQrpd49jtNuw5WMLG7AI2ZhWwZlc+qzLz+GhNVq2njwgKIMjlpKisovqLYkBqLL+7oAvp7epxx6JOjdsNuZvs33s3+LYsXqKBXzUfQeFw7XvHP6ZVD7hhLqx8zTYLvXQhXP/h0aki8nba2l7fybW3dxgGXz1iZyUHRcKih6HP1fZO4KO7YdF/4NzfHrcIDoeQFB1CUnQIw7ocXsoy91Ap6/cUkH2whOyCEvYeLKW0wk14kJPQwACMMby5NIPLn/6WYV1a8ItzbZn3FZSSc6iUSrchKsRFTKj9suncMlyHnZ6K/Ay7El1ovG3yqSwHZ/N6HzXwK//jcEC/ayGpvx0KWhX8a07M2viJ/d35iGwibc60+YXWvWdH+8S0s/0LgeG2Q3DBQ5DUFzqOPOlixYUHMbjT8ZPM3TK0I9O+3c5TC7cw6dnFx3+ZAt0SIxnQLo4BqTH0TYmhZWTwSZfL71S173cdAyum2YmCLbr4tkwNTAO/8l8tu9uAP+1ieHkMTH4XDmyH1dNt4I/rBHEda58TEARtz4LVb4EjAG781M4hALh4KmSvsx3J17wHiX1qn1teAqvftknpek88pSKHBDq5+dwOXDkghW825xAZYkcNtYgIIsAp5BWWc6CojNzCUlZl5PPdtv28vmQHL369DYBWkcH0aRNN27hQOyvCGALdRURERNMmLow2MaEkRgcTFeLy3/kJVYG/2zgb+Peu18CvVLOSkAbXeYL/04PttrAEOwz0zCl1d/62H2YzjA77vb1rqBIYBhNftQvVPHuuTTQ38BZoezYsfxkWPwmH7LBPivfbfacoKmsxo1f8Gy5+FGLjq7dHBrtIibOTjoZ3bQnYhW3W7jrIqow8VmbkEbvtQ8ZsnkUc+bQgj0CpYKM7ibcrh/H7ysEcwPZphLicRAQHEBMaSMuoYFpFBtEqMphuiZH0bxtLi4hmmgI7ZyOExkHKIEBs4O8+3telalA6gUspgJxNsPQF6DQSUofWngF8pNIC2DAHek4ARx2jbIr2w4pX4Lvn4GCm7fg1btsxfPbtdr2C9R/AmEfgjBtPvqwHtsOzQ+1EtvjO9q4jJKZ+55YVwSNpdoRSmzMhPAGCIqhY/zEBe5bjdrjYGX8uGWE92BHYkS2OVDJLg8k+WEJWfgn7DpVWp7ZoGxdK/7Yx9E6OpodnmOqxRh253YaySnfTWEP5xdGAgZ/Nhf/1hVY94YpXfF2qU6Izd5U63SorYMOHdj5AzwmQ1M9uryiD6dfAxrmH5xrUV1kRvHg+HNgJFzwEH/4GUgbC5Jl25NKJLJ8GH9xWd26j7HX2C+uH2VCw5/D2buNgwjQQqb57WL5jP0u3H2DFjgPkFpYB4HQILSOCCHY5CQxwEBjg4FBpBXlF5eQVleE2EB8eRPv4MFLjw4iPOFxeQWgbF0qfNtG0bxGO0yEYY8g+aLOtxoYFnr6lNv/VAbpeaCf8vXkV5G6GX313ep67gWngV6oxKS+xs4u3fG47lSvL7Y8rBM76FfS95ui7CWNg5hS70P1V0+3EslVvw6wp0PsqOzT1ePMSjDncnHXzV8c/9tA+u3bC+g9tuuwrXoVuY+u4pGFPfglrdtllMffkl1BW6aasopLSCjdhQQHEhNqRRkEBDjL2F7Mtp5CtOYc4UFROVQncxuBZRoHwoABSYkPJOFBEQY1JcCPTErj7gi50bRV5VBmOm1b7ZBTth3+l2iVFz/o1zP8LfDUVfr/H9u80MZqyQanGxBUMk16HeQ/Y2rUz0A4Z3PcjfHA7LHnWzjDuOMJ+IRTssUF+zXQY/n+HZxP3nggHttnJaVFJtt/hWEFwx9c22d3Yx068pkB4CwgfbhPc7fgGPvuDHeF0RPATERKjQ0iMDuGC7q1O+e1wuw1bcwpZlZHHqsw8tucW0b9tDJ1bhtMhIZyVGXk8tXALox9dxLjeicSHB7Fx7yE2ZRewr6CUzi0j6N0mmt7JUYQEOvlhz0F+2H2QTdmH6JEUxbWD2jK4Y/yJU2bkeMbvx3s6cxO6gam0tf660oU0URr4lfIVVwiM/kftbcbYppbP/givXWo7GYv2U52ZtOtFMPiu2uecew/kZdgFYw7ugYv+W3ezz5JnbF9Azwn1L6MzwDYpvXapPf/s22rvd7tPmPm0PhwOoWNCOB0TwrmsxuznKmd1iOeqASk8/cVWXvKMUOqYEM7A9nHEhweyIauAOat38+53W3BRQbkzjM6twjkjNZZvNucwb302qfFhjO+TRIBTKC6rpKz4IPHBDs7q2ZHuiZH2riHnR/uEVUN7W3S1v/eu18CvlPISETuCpMto2wmcvc6u/BWZCFHJNl/QkYFWBMY9bvd/8Q877nziaxAWd/iY/EzbIX3Wr+pe1OZ4Oo6ATufbL5beV9q7gbJCu67y2plw3ft2ApuXRYcGcu/ortwxshMup+OopTPdGcupnH4t7oAQHL/8BpfLfvmVVlQyd20Wr3y7g//Os0M1HQKvBP6TliaH8xb+i1aRIQzr2oIJ+7+jlyOQV9ZVgmyjqEj4JU7mf7GQmatSKatwU1bpprzSTVJ0KN0TI+mRFEXbuFB25xWzPbeQbTlFRAQFMK5vIgkRjXPehLbxK9WcrJkB7/3SLnx/4cN2qUuH0zYpfT0Vbl9l1z4+Wfs2wpMDof91NtHdzJvsF0xQJES0hClf+C53vTF2BNUn99sylOTDpc9BryuOOvRgSTmBTgdBOWuRZ84BYOHAF3k7px2LNuUw1f13kiSX0WWH78TmB91NpjOZB8P/r7rTulvFer7Pj+CHwvCjnkPEFsnpEIZ3TeDy/smUVbj5fmceK3YeYOu+Q0R5srbGhweRGh/GWR3iGJAaWys/U0PQzl2l/EXmMpuJtGAPhLey/QArXrUTzya9furX/eh3sPQ5QCCitV3jwFTCK+NgwBS48N+1j68ohdwtNu9NziaoLLMdplUT3hpCWSHM/hWsmwmdLoDxT9k5Ge5y+OXiuofbgu0kX/+hnYTX+QK47DmMMfC/vlS26k3hxc/jNobw4ABcM66zd163rbDn7lxiR1Y5XBR3n8TKttezqTyexKgQ2sWH0SY2hIz9xbyzLIN3V2SSc8iOegp2OeiVFE2XVhEUlJSTc6iMfQWlbMsppKzSjcsp9G0TQ7fESNrGhdIuLoyUuFBSYkNxneJkOg38SvmTilI7+3jVm7DpU3BXwHUfeFJLn6Ki/fDccEg+wwb5kGi7fe59dnLa5Hdtqgp3pZ0T8fmDUJpf4wICyelw9YzD556IuxK+fNhOeDvvL7U7l8uK7GI7O76G4X+As++wzWBrZ8KMG+Dyl+z6DEfK3wWP9oIzbrLvy4pX4O4fISAE/tbaJvsbdv/h4xf8zTZz3b/bflE8c45N0tf5Apvoz10BvSfZO6wj7nrKK90s3ppLdEggXVtH1BnAi8sqWbp9P19vyWHxllw27z1EYY3srXPvGHLUSKb60lE9SvmTgCA7/LLbWDs0M+dHaDf4p10zNBZuX3n09hF/tMNS37sVxj0B8x+ArNV2wlrfa2zai7iOsHUhvHO9vUO4ZtaJ10QoybfpLzZ9ah/vWW3vWEJjDw+H3f6Vp1mnRod1t3F2YtuX/7YrtR3ZJ/LdM3ZC3cCbbQBf+hysfse+P8Ztz60pIc1uz9loU3Lv/cFmYe16of2S+OYx+8Vn3PaOo8aIKZfTwZBOLY77MkMCnZzTuQXndLbHGWPILSxjR24h23OKaBcXdvz36RRo4FequQtvYX+8xRVig+9zw+H1y2zz0uUvQfdLag8bTbvIBu63J9vkeBc/aoeX7lwMu1dATKrt1O48ys6OfutK248w5hEIjrJ9F8+PhElv2OGlWxfAuCdrB32wzTtD7rbzG36cU3vVtdICWPYypI21CfYAWvexOXmq3qMjA3+LNPt746c2+2rXi2zQB9uXMupvNkX3wr/bFB4DbvpJb6eIVLf/92/rnfTb2tSjlGoYq6fbeQhn3157DYMjbZ5va+sVJfZxaBwk9oN9G2xKZLCJ7FyhNvdR1Z3KzsXw5pU2VQXGLrZz5LoLVSor4IkzbNbUX3x5+Ato8VMw9174+Xzb7AS2WWrOndDlQvjxI7h/T+0mm8pyeKi1rdG7QuDWJXYEVU1uN7w50d4R3PARtBlwUm+dt2gbv1Kq8chaY5tu2gywzUBVQ2Gy18GPH9tJaef+7nCtvEruFnj/Nuh5mU2kdzzfvwazb7WjkNoMsJOx3v0ZRCTCjZ8cPq4kHx7uAhXFEJUCv1lz9LWeHGSbeC74m13prS7FB2wOpYpS+2UTnlD3cW437F0HW7+AbV/CoSw7vyI42v4Ojav9k3LmKXeIa+BXSvmXynLbp7BlAZQXHt4+8bXazT8As26BVW/YzunJ7x59rbn3wa4VcP2c4yfwy1oDz59nA3aHoTbDZ1K6zcq6a5kdcZWxBIpy7fFxHW0TV0m+/eKo+jGHO3e5dSm06Fzn052Idu4qpfyL02X7FNxuyNthZ9+W5EOXMUcf2+9aG/iPbN+vMurv9o7kRKkuWvW0z/nds3a46Pev1d4f18kOO00dAqnn2jQbR3K77Wioov32C+JU5l2cgNb4lVLKGLt+ctrFDZeawe0ZCbR7hW32Sepf//TZDURr/EopdSwiMPTehr2mwwEJXe1PI+Ona6sppZT/0sCvlFJ+RgO/Ukr5GQ38SinlZzTwK6WUn9HAr5RSfkYDv1JK+RkN/Eop5WeaxMxdEdkH7DjF0+OBnAYsTnOk71H96Pt0YvoendjpfI/aGmOOysndJAL/TyEiy+qasqwO0/eofvR9OjF9j06sMbxH2tSjlFJ+RgO/Ukr5GX8I/M/6ugBNgL5H9aPv04npe3RiPn+Pmn0bv1JKqdr8ocavlFKqBg38SinlZ5p14BeRUSLyo4hsFpEGXmWhaRKRNiKyQER+EJF1InK7Z3usiHwmIps8v0/vUkGNkIg4ReR7EfnQ8zhVRJZ4Pk9vi0igr8voayISLSIzRGSDiKwXkUH6WapNRH7j+V9bKyJvikiwrz9LzTbwi4gTeAIYDXQDrhSRbr4tVaNQAdxljOkGDARu9bwv9wLzjTGdgPmex/7udmB9jcf/BP5rjOkIHABu9EmpGpdHgbnGmK5Ab+z7pZ8lDxFJAm4D0o0xPQAnMAkff5aabeAHBgCbjTFbjTFlwFvAOB+XyeeMMXuMMSs8fxdg/1GTsO/NNM9h04Dxvilh4yAiycAY4HnPYwGGAzM8h+h7JBIFnAO8AGCMKTPG5KGfpSMFACEiEgCEAnvw8WepOQf+JCCjxuNMzzblISLtgL7AEqClMWaPZ1cW0NJHxWospgK/A9yex3FAnjGmwvNYP0+QCuwDXvI0iT0vImHoZ6maMWYX8DCwExvw84Hl+Piz1JwDvzoOEQkH3gXuMMYcrLnP2DG+fjvOV0QuAvYaY5b7uiyNXADQD3jKGNMXKOSIZh39LEkM9g4oFUgEwoBRPi0UzTvw7wLa1Hic7Nnm90TEhQ36rxtjZno2Z4tIa8/+1sBeX5WvETgbGCsi27FNhMOxbdnRntt10M8T2JpqpjFmiefxDOwXgX6WDhsJbDPG7DPGlAMzsZ8vn36WmnPgXwp08vSeB2I7VN73cZl8ztNW/QKw3hjzSI1d7wPXef6+Dph9usvWWBhj7jPGJBtj2mE/N58bY64GFgCXew7z6/cIwBiTBWSISBfPphHAD+hnqaadwEARCfX871W9Rz79LDXrmbsiciG2rdYJvGiMecjHRfI5ERkMLALWcLj9+n5sO/90IAWbAvsKY8x+nxSyERGRocDdxpiLRKQ99g4gFvgemGyMKfVl+XxNRPpgO8ADga3ADdgKpX6WPETkAWAidkTd98DPsW36PvssNevAr5RS6mjNualHKaVUHTTwK6WUn9HAr5RSfkYDv1JK+RkN/Eop5Wc08CvlZSIytCrDp1KNgQZ+pZTyMxr4lfIQkcki8p2IrBSRZzz5+A+JyH89+dTni0gLz7F9RGSxiKwWkVlVOedFpKOIzBORVSKyQkQ6eC4fXiNv/eueWZxK+YQGfqUAEUnDzq482xjTB6gErsYm1VpmjOkOfAH8yXPKK8A9xphe2FnQVdtfB54wxvQGzsJmZASbBfUO7NoQ7bH5WpTyiYATH6KUXxgB9AeWeirjIdjkYm7gbc8xrwEzPXnoo40xX3i2TwPeEZEIIMkYMwvAGFMC4Lned8aYTM/jlUA74CvvvyyljqaBXylLgGnGmPtqbRT5wxHHnWqOk5p5WCrR/z3lQ9rUo5Q1H7hcRBKgeg3ittj/kaosilcBXxlj8oEDIjLEs/0a4AvPimaZIjLec40gEQk9ra9CqXrQWodSgDHmBxH5P+BTEXEA5cCt2MVFBnj27cX2A4BNpfu0J7BXZaUE+yXwjIj8xXONCafxZShVL5qdU6njEJFDxphwX5dDqYakTT1KKeVntMavlFJ+Rmv8SinlZzTwK6WUn9HAr5RSfkYDv1JK+RkN/Eop5Wf+H3kocNK7joJNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1146/1146 [==============================] - 15s 13ms/step - loss: 23.3688 - r2_keras: 0.7007\n",
            "[23.368824005126953, 0.7007029056549072]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_future = model_1.predict(X_test)"
      ],
      "metadata": {
        "id": "dbaKMIjE8Px1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ERROR DISTRIBUTION\n",
        "\n",
        "according the label"
      ],
      "metadata": {
        "id": "toAHgYSrG-Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, dir_labels = data_for_plot(predictions_future, y_test)\n",
        "ks_boxplots(data,  f\"LSTM-v0_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}_error\", dir_labels, outliers=False)"
      ],
      "metadata": {
        "id": "evfwiNN38SQR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d5864bc-6fb5-4aba-8dfa-504ded0c86b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN-LSTM v.0\n"
      ],
      "metadata": {
        "id": "vTkRQGaBKopo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - better be parameters of function\n",
        "DROPOUT_RATE = .1\n",
        "N_NODES = 512\n",
        "LSTM_NODES = 256\n",
        "\n",
        "def CNN1_LSTM_model(number_of_classes=2, learning_rate=1e-4, input_shape=None):\n",
        "    model = Sequential([\n",
        "      Conv2D(filters=64, kernel_size=(3,3), padding='same', activation=\"relu\", input_shape=input_shape),\n",
        "      Conv2D(filters=64, kernel_size=3, padding='same', activation=\"relu\"),   # TODO tu bolo Conv1D nechtiac, ale ide\n",
        "      MaxPooling2D(pool_size=2),\n",
        "      TimeDistributed(Flatten()),\n",
        "      LSTM(LSTM_NODES, activation=\"relu\", return_sequences=False),\n",
        "      Dense(N_NODES, activation=\"relu\"),\n",
        "      Dense(1, activation=\"linear\"),                    \n",
        "    ])\n",
        "\n",
        "    \n",
        "    # loss_f = tf.keras.losses.MeanSquaredError()\n",
        "    # loss_f = tf.keras.losses.MeanAbsoluteError()\n",
        "    loss_f = tf.keras.losses.MeanAbsolutePercentageError()\n",
        "    # loss_f = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "    \n",
        "    # lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    #     initial_learning_rate=1e-2,\n",
        "    #     decay_steps=10000,\n",
        "    #     decay_rate=0.9\n",
        "    # )\n",
        "\n",
        "    model.compile(\n",
        "      loss=loss_f,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "      metrics=[r2_keras]\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RFSRT5CQC_5s"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_12 = CNN1_LSTM_model(learning_rate=1e-4, input_shape=X_train_CNN[0].shape)"
      ],
      "metadata": {
        "id": "lYGdG5OJDy4d"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath=f'{f\"{SAVE_PATH}/CNN-LSTM-v0_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}\"}.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history_12 = model_12.fit(X_train, y_train, shuffle=True, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=64, callbacks=[es, rlr, mcp, tb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "18ABEq34F4DY",
        "outputId": "c25e46cf-ccf7-4da7-b6b8-10b7109b7a29"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            " 355/4125 [=>............................] - ETA: 7:08 - loss: 113.7577 - r2_keras: -0.2311"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-93a6ccb6139f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory_12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_12\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_acc_loss(history_12, f\"CNN-LSTM-v0_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_COLUMNS}\")\n",
        "\n",
        "print('\\n\\n')\n",
        "score = model_12.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'{score}')\n",
        "\n",
        "out_file = open(f'{SAVE_PATH}/statistics.txt', \"a\")\n",
        "out_file.write(f\"CNN-LSTM-v0 \\t {score}\")\n",
        "out_file.close()"
      ],
      "metadata": {
        "id": "h9dr6sOnR4DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_future = model_12.predict(X_test)"
      ],
      "metadata": {
        "id": "NzZxEM9GRr9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, dir_labels = data_for_plot(predictions_future, y_test)\n",
        "ks_boxplots(data,  f\"CNN-LSTM-v0_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}_error\", dir_labels, outliers=False)"
      ],
      "metadata": {
        "id": "_OV-SRh1v_M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(predictions_future, y_test):\n",
        "  print(i, j)"
      ],
      "metadata": {
        "id": "kGJhoM52SlRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN-LSTM v.1\n"
      ],
      "metadata": {
        "id": "cS9G3qJXC-PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - better be parameters of function\n",
        "DROPOUT_RATE = .1\n",
        "N_NODES = 512\n",
        "LSTM_NODES = 256\n",
        "\n",
        "def CNN1_LSTM_model(number_of_classes=2, learning_rate=1e-4, input_shape=None):\n",
        "    model = Sequential([\n",
        "      Conv2D(filters=64, kernel_size=(3,3), padding='same', activation=\"relu\", input_shape=input_shape),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      Conv2D(filters=64, kernel_size=3, padding='same', activation=\"relu\"),   # TODO tu bolo Conv1D nechtiac, ale ide\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPooling2D(pool_size=2),\n",
        "      TimeDistributed(Flatten()),\n",
        "      LSTM(LSTM_NODES, activation=\"relu\", return_sequences=False),\n",
        "      Dense(N_NODES, activation=\"relu\"),\n",
        "      Dense(1, activation=\"linear\"),                    \n",
        "    ])\n",
        "\n",
        "    \n",
        "    # loss_f = tf.keras.losses.MeanSquaredError()\n",
        "    # loss_f = tf.keras.losses.MeanAbsoluteError()\n",
        "    loss_f = tf.keras.losses.MeanAbsolutePercentageError()\n",
        "    # loss_f = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "    \n",
        "    # lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    #     initial_learning_rate=1e-2,\n",
        "    #     decay_steps=10000,\n",
        "    #     decay_rate=0.9\n",
        "    # )\n",
        "\n",
        "    model.compile(\n",
        "      loss=loss_f,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "      metrics=[r2_keras]\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "R4llu9hMC1lx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = CNN1_LSTM_model(learning_rate=1e-4, input_shape=X_train_CNN[0].shape)"
      ],
      "metadata": {
        "id": "5LbWhV7fC1ly"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath=f\"{SAVE_PATH}/CNN-LSTM-v0_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history_2 = model_2.fit(X_train, y_train, shuffle=True, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=64, callbacks=[es, rlr, mcp, tb])"
      ],
      "metadata": {
        "id": "2RTSGWxwC1ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a9c5e8-c479-4189-e9fd-5f7d23c60bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 56.5744 - r2_keras: 0.3411\n",
            "Epoch 00001: val_loss improved from inf to 39.48983, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 493s 119ms/step - loss: 56.5744 - r2_keras: 0.3411 - val_loss: 39.4898 - val_r2_keras: 0.4838 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 38.6114 - r2_keras: 0.4950\n",
            "Epoch 00002: val_loss improved from 39.48983 to 37.34261, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 509s 123ms/step - loss: 38.6114 - r2_keras: 0.4950 - val_loss: 37.3426 - val_r2_keras: 0.5007 - lr: 1.0000e-04\n",
            "Epoch 3/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 36.0068 - r2_keras: 0.5311\n",
            "Epoch 00003: val_loss improved from 37.34261 to 35.92660, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 507s 123ms/step - loss: 36.0068 - r2_keras: 0.5311 - val_loss: 35.9266 - val_r2_keras: 0.5031 - lr: 1.0000e-04\n",
            "Epoch 4/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 34.1022 - r2_keras: 0.5529\n",
            "Epoch 00004: val_loss improved from 35.92660 to 32.65454, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 486s 118ms/step - loss: 34.1022 - r2_keras: 0.5529 - val_loss: 32.6545 - val_r2_keras: 0.5698 - lr: 1.0000e-04\n",
            "Epoch 5/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 32.4411 - r2_keras: 0.5694\n",
            "Epoch 00005: val_loss improved from 32.65454 to 31.03771, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 491s 119ms/step - loss: 32.4411 - r2_keras: 0.5694 - val_loss: 31.0377 - val_r2_keras: 0.5795 - lr: 1.0000e-04\n",
            "Epoch 6/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 31.0897 - r2_keras: 0.5857\n",
            "Epoch 00006: val_loss improved from 31.03771 to 29.48161, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 474s 115ms/step - loss: 31.0897 - r2_keras: 0.5857 - val_loss: 29.4816 - val_r2_keras: 0.6033 - lr: 1.0000e-04\n",
            "Epoch 7/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 30.1467 - r2_keras: 0.5925\n",
            "Epoch 00007: val_loss did not improve from 29.48161\n",
            "4125/4125 [==============================] - 471s 114ms/step - loss: 30.1467 - r2_keras: 0.5925 - val_loss: 31.2416 - val_r2_keras: 0.5842 - lr: 1.0000e-04\n",
            "Epoch 8/1000\n",
            "4125/4125 [==============================] - ETA: 0s - loss: 29.2932 - r2_keras: 0.6077\n",
            "Epoch 00008: val_loss improved from 29.48161 to 28.35612, saving model to /content/gdrive/MyDrive/phd_UNIZA/NN_regression_ks/W_10_A_30_X_xy/CNN-LSTM-v0_LF_mape_W_10_A_30_SC_xy.h5\n",
            "4125/4125 [==============================] - 473s 115ms/step - loss: 29.2932 - r2_keras: 0.6077 - val_loss: 28.3561 - val_r2_keras: 0.6516 - lr: 1.0000e-04\n",
            "Epoch 9/1000\n",
            "1728/4125 [===========>..................] - ETA: 4:21 - loss: 28.9080 - r2_keras: 0.6094"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_acc_loss(history_2, f\"CNN-LSTM-v1_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}\")\n",
        "\n",
        "print('\\n\\n')\n",
        "score = model_2.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'{score}')\n",
        "\n",
        "out_file = open(f'{SAVE_PATH}/statistics.txt', \"a\")\n",
        "out_file.write(f\"CNN-LSTM-v1 \\t {score}\")\n",
        "out_file.close()"
      ],
      "metadata": {
        "id": "mo3IVcCJC1ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_future = model_2.predict(X_test)"
      ],
      "metadata": {
        "id": "bD45BfelC1ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, dir_labels = data_for_plot(predictions_future, y_test)\n",
        "ks_boxplots(data,  f\"CNN-LSTM-v1_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}_error\", dir_labels, outliers=False)"
      ],
      "metadata": {
        "id": "u5sN7bZ0C1ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(predictions_future, y_test):\n",
        "  print(i, j)"
      ],
      "metadata": {
        "id": "Ta5znFlfC1lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN-LSTM v.2\n",
        "\n",
        "- using Conv1D\n"
      ],
      "metadata": {
        "id": "Crfz7GqwhFFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - better be parameters of function\n",
        "DROPOUT_RATE = .1\n",
        "N_NODES = 512\n",
        "LSTM_NODES = 256\n",
        "\n",
        "def CNNv2_LSTM_model(number_of_classes=2, learning_rate=1e-4, input_shape=None):\n",
        "    model = Sequential([\n",
        "      Conv1D(filters=64, kernel_size=len(SELECTED_COLUMNS), padding='same', activation=\"relu\", input_shape=input_shape),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      Conv1D(filters=64, kernel_size=len(SELECTED_COLUMNS), padding='same', activation=\"relu\"),   # TODO tu bolo Conv1D nechtiac, ale ide\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPooling1D(pool_size=2),\n",
        "      TimeDistributed(Flatten()),\n",
        "      LSTM(LSTM_NODES, activation=\"relu\", return_sequences=False),\n",
        "      Dense(N_NODES, activation=\"relu\"),\n",
        "      Dense(1, activation=\"linear\"),                    \n",
        "    ])\n",
        "\n",
        "    \n",
        "    # loss_f = tf.keras.losses.MeanSquaredError()\n",
        "    # loss_f = tf.keras.losses.MeanAbsoluteError()\n",
        "    loss_f = tf.keras.losses.MeanAbsolutePercentageError()\n",
        "    # loss_f = tf.keras.losses.MeanSquaredLogarithmicError()\n",
        "    \n",
        "    # lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    #     initial_learning_rate=1e-2,\n",
        "    #     decay_steps=10000,\n",
        "    #     decay_rate=0.9\n",
        "    # )\n",
        "\n",
        "    model.compile(\n",
        "      loss=loss_f,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "      metrics=[r2_keras]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "468sJKxEhFFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = CNNv2_LSTM_model(learning_rate=1e-4, input_shape=X_train[0].shape)"
      ],
      "metadata": {
        "id": "6_5TdVJbhFFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath=f\"{SAVE_PATH}/CNN1-LSTM-v2_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history_2 = model_2.fit(X_train, y_train, shuffle=True, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=64, callbacks=[es, rlr, mcp, tb])"
      ],
      "metadata": {
        "id": "OuCB71VUhFFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_acc_loss(history_2, f\"CNN1-LSTM-v2_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}\")\n",
        "\n",
        "print('\\n\\n')\n",
        "score = model_2.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'{score}')\n",
        "\n",
        "out_file = open(f'{SAVE_PATH}/statistics.txt', \"a\")\n",
        "out_file.write(f\"CNN1-LSTM-v2 \\t {score}\")\n",
        "out_file.close()"
      ],
      "metadata": {
        "id": "YBU8IrGkhFFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_future = model_2.predict(X_test)"
      ],
      "metadata": {
        "id": "P6FCy_ZFhFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, dir_labels = data_for_plot(predictions_future, y_test)\n",
        "ks_boxplots(data,  f\"CNN1-LSTM-v2_LF_{LOSS_FN}_W_{TS_LENGTH}_A_{NUMBER_OF_AUGMENTATION}_SC_{SELECTED_AXES}_error\", dir_labels, outliers=False)"
      ],
      "metadata": {
        "id": "AKEYF2inhFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(predictions_future, y_test):\n",
        "  print(i, j)"
      ],
      "metadata": {
        "id": "bzJ-Sdo8hFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RESNET like"
      ],
      "metadata": {
        "id": "hltWzDv1WSlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, out_chanels, kernel_size=3):\n",
        "    super(CNNBlock, self).__init__()\n",
        "    self.conv = tf.keras.layers.Conv2D(out_chanels, len(SELECTED_COLUMNS), padding='same')\n",
        "    self.bn = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.conv(input_tensor)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "F4Y2Ae6qV0f4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-oqL8nYTs74u"
      },
      "outputs": [],
      "source": [
        "class ResBlock(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, channels):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.conn1 = CNNBlock(channels[0])\n",
        "    self.conn2 = CNNBlock(channels[1])\n",
        "    self.conn3 = CNNBlock(channels[2])\n",
        "\n",
        "    self.pooling = tf.keras.layers.MaxPooling2D()\n",
        "    self.identity_mapping = tf.keras.layers.Conv2D(channels[1], 1, padding='same')\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.conn1(input_tensor, training=training)\n",
        "    x = self.conn2(x, training=training)\n",
        "    x = self.conn3(\n",
        "        x + self.identity_mapping(input_tensor, training=training),\n",
        "        training=training\n",
        "    )\n",
        "\n",
        "    return self.pooling(x)\n",
        "\n",
        "\n",
        "class ResNet_Like(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, number_of_outputs=1):\n",
        "    super(ResNet_Like, self).__init__()\n",
        "    self.block1 = ResBlock([32,64,128])\n",
        "    self.block2 = ResBlock([128,128,256])\n",
        "    self.block3 = ResBlock([128,256,512])\n",
        "\n",
        "    self.pool = tf.keras.layers.GlobalAveragePooling2D()  # same as Flatten alegidly\n",
        "    self.classifier = tf.keras.layers.Dense(number_of_outputs)\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.block1(input_tensor, training=training)\n",
        "    x = keras.layers.Dropout(.2)(x)\n",
        "    x = self.block2(x, training=training)\n",
        "    x = keras.layers.Dropout(.2)(x)\n",
        "    x = self.block3(x, training=training)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    return self.classifier(x)\n",
        "\n",
        "  def model(self):\n",
        "    x = keras.Input(sape=(28,28,1))\n",
        "    return keras.Model(inputs=[x], outputs=self.call(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cOIIlnRdwXV-"
      },
      "outputs": [],
      "source": [
        "model_3 = ResNet_Like(number_of_outputs=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath=f'{SAVE_PATH}/weights_ResNet.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "tb = TensorBoard('logs')"
      ],
      "metadata": {
        "id": "gD72pv_CYH3u"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SPSw4dZ7qR4J",
        "outputId": "ab1ddd55-7581-4507-b964-b8f90b938244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6aa340d9a9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"res_net__like_1\" (type ResNet_Like).\n    \n    in user code:\n    \n        File \"<ipython-input-43-921e47cfb6c0>\", line 37, in call  *\n            x = self.block2(x, training=training)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"res_block_4\" (type ResBlock).\n        \n        in user code:\n        \n            File \"<ipython-input-43-921e47cfb6c0>\", line 20, in call  *\n                return self.pooling(x)\n            File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            ValueError: Exception encountered when calling layer \"max_pooling2d_5\" (type MaxPooling2D).\n            \n            Negative dimension size caused by subtracting 2 from 1 for '{{node res_net__like_1/res_block_4/max_pooling2d_5/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](res_net__like_1/res_block_4/cnn_block_14/Relu)' with input shapes: [?,1,10,256].\n            \n            Call arguments received:\n              â€¢ inputs=tf.Tensor(shape=(None, 1, 10, 256), dtype=float32)\n        \n        \n        Call arguments received:\n          â€¢ input_tensor=tf.Tensor(shape=(None, 1, 10, 128), dtype=float32)\n          â€¢ training=True\n    \n    \n    Call arguments received:\n      â€¢ input_tensor=tf.Tensor(shape=(None, 3, 21, 1), dtype=float32)\n      â€¢ training=True\n"
          ]
        }
      ],
      "source": [
        "# model_3.compile(\n",
        "#     loss=keras.losses.MeanSquaredError(),\n",
        "#     optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "#     metrics=[\"mean_squared_error\"]\n",
        "# )\n",
        "\n",
        "model_3.compile(\n",
        "  loss=tf.keras.losses.MeanAbsoluteError(),\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "  metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
        ")\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "history_3 = model_3.fit(\n",
        "    X_train_CNN,\n",
        "    y_train_CNN, \n",
        "    shuffle=True, \n",
        "    epochs=EPOCHS, \n",
        "    validation_split=0.2, \n",
        "    verbose=2, \n",
        "    batch_size=64, \n",
        "    callbacks=[es, rlr, mcp, tb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_acc_loss(history_3, \"ResNet\")\n",
        "\n",
        "print('\\n\\n')\n",
        "score = model_3.evaluate(X_test_CNN, y_test_CNN, verbose=1)\n",
        "print(f'{score}')\n",
        "\n",
        "out_file = open(f'{SAVE_PATH}/statistics.txt', \"a\")\n",
        "out_file.write(f\"ResNet \\t {score}\")\n",
        "out_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "-ml_chXEZxiN",
        "outputId": "7b80cc54-263c-48b0-8b2f-543ce1846d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "9/9 [==============================] - 1s 33ms/step - loss: 0.0786 - mean_absolute_error: 0.0786\n",
            "[0.07864200323820114, 0.07864200323820114]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_future = model_3.predict(X_test_CNN)"
      ],
      "metadata": {
        "id": "IKSvpmlyZey0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(predictions_future, y_test):\n",
        "  print(i, j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce12ad64-6422-4422-eee1-01cd5d196584",
        "id": "bDBugcQcZey6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.30649036] 0.15\n",
            "[0.26522994] 0.225\n",
            "[0.27751085] 0.005\n",
            "[0.13261746] 0.05\n",
            "[0.28575572] 0.05\n",
            "[0.11345769] 0.3\n",
            "[0.25523382] 0.3\n",
            "[0.09779118] 0.1\n",
            "[0.2783326] 0.05\n",
            "[0.0847549] 0.15\n",
            "[0.21091358] 0.015\n",
            "[0.32342246] 0.15\n",
            "[0.16042523] 0.05\n",
            "[0.31511965] 0.03\n",
            "[0.24233885] 0.1\n",
            "[0.22078563] 0.3\n",
            "[0.0727254] 0.225\n",
            "[0.12602912] 0.03\n",
            "[0.3027036] 0.015\n",
            "[0.16533493] 0.15\n",
            "[0.27652562] 0.3\n",
            "[0.1196803] 0.015\n",
            "[0.27564254] 0.3\n",
            "[0.04603131] 0.15\n",
            "[0.10328992] 0.3\n",
            "[0.19550015] 0.009\n",
            "[0.31079975] 0.03\n",
            "[0.21239866] 0.03\n",
            "[0.26986176] 0.3\n",
            "[0.12517704] 0.05\n",
            "[0.27786833] 0.03\n",
            "[0.21784608] 0.05\n",
            "[0.11511578] 0.015\n",
            "[0.22074668] 0.3\n",
            "[0.2711049] 0.015\n",
            "[0.21719365] 0.15\n",
            "[0.11786328] 0.009\n",
            "[0.30196896] 0.225\n",
            "[0.2874422] 0.15\n",
            "[0.27544993] 0.05\n",
            "[0.17318659] 0.03\n",
            "[0.10768406] 0.015\n",
            "[0.21198712] 0.03\n",
            "[0.10114442] 0.005\n",
            "[0.26999062] 0.03\n",
            "[0.07425709] 0.05\n",
            "[0.23669763] 0.015\n",
            "[0.30256206] 0.009\n",
            "[0.20830058] 0.1\n",
            "[0.07507379] 0.005\n",
            "[0.12158559] 0.03\n",
            "[0.16765137] 0.1\n",
            "[0.21349941] 0.225\n",
            "[0.27240446] 0.05\n",
            "[0.11325417] 0.03\n",
            "[0.26386112] 0.015\n",
            "[0.07984371] 0.1\n",
            "[0.23962803] 0.015\n",
            "[0.15905602] 0.225\n",
            "[0.14935528] 0.03\n",
            "[0.3309007] 0.3\n",
            "[0.04828118] 0.009\n",
            "[0.07135163] 0.005\n",
            "[0.13093524] 0.015\n",
            "[0.10455243] 0.3\n",
            "[0.2246855] 0.3\n",
            "[0.16364883] 0.1\n",
            "[0.08753245] 0.225\n",
            "[0.1417995] 0.03\n",
            "[0.08122863] 0.225\n",
            "[0.1257687] 0.005\n",
            "[0.2703337] 0.15\n",
            "[0.18427561] 0.3\n",
            "[0.20610972] 0.225\n",
            "[0.10620232] 0.05\n",
            "[0.11788525] 0.015\n",
            "[0.09861581] 0.05\n",
            "[0.27614528] 0.15\n",
            "[0.08986036] 0.15\n",
            "[0.08343355] 0.005\n",
            "[0.20797415] 0.005\n",
            "[0.2486427] 0.005\n",
            "[0.13653354] 0.05\n",
            "[0.28971425] 0.015\n",
            "[0.10592328] 0.005\n",
            "[0.03930278] 0.03\n",
            "[0.26925275] 0.03\n",
            "[0.13565667] 0.3\n",
            "[0.10325594] 0.3\n",
            "[0.15673865] 0.005\n",
            "[0.26119047] 0.05\n",
            "[0.08847629] 0.015\n",
            "[0.13204877] 0.3\n",
            "[0.20727812] 0.005\n",
            "[0.18037565] 0.009\n",
            "[0.27555755] 0.05\n",
            "[0.27005523] 0.225\n",
            "[0.24373473] 0.03\n",
            "[0.18944307] 0.05\n",
            "[0.2933087] 0.015\n",
            "[0.07801972] 0.005\n",
            "[0.075772] 0.225\n",
            "[0.29951996] 0.15\n",
            "[0.30738178] 0.015\n",
            "[0.28877133] 0.015\n",
            "[0.2323048] 0.009\n",
            "[0.17450581] 0.015\n",
            "[0.09802933] 0.03\n",
            "[0.13489394] 0.009\n",
            "[0.17860813] 0.005\n",
            "[0.0426728] 0.05\n",
            "[0.14014877] 0.3\n",
            "[0.14589567] 0.225\n",
            "[0.31670198] 0.225\n",
            "[0.04024826] 0.15\n",
            "[0.08729525] 0.005\n",
            "[0.18584926] 0.03\n",
            "[0.23885976] 0.015\n",
            "[0.25648478] 0.03\n",
            "[0.13964994] 0.009\n",
            "[0.07796864] 0.009\n",
            "[0.12589766] 0.009\n",
            "[0.11733232] 0.015\n",
            "[0.14607506] 0.3\n",
            "[0.12651701] 0.05\n",
            "[0.27962133] 0.15\n",
            "[0.13573076] 0.3\n",
            "[0.26907605] 0.1\n",
            "[0.285863] 0.005\n",
            "[0.09808414] 0.03\n",
            "[0.08817141] 0.005\n",
            "[0.08649714] 0.03\n",
            "[0.12210512] 0.1\n",
            "[0.10748173] 0.005\n",
            "[0.147566] 0.3\n",
            "[0.09363411] 0.03\n",
            "[0.2803024] 0.015\n",
            "[0.20775838] 0.05\n",
            "[0.3119255] 0.225\n",
            "[0.18174772] 0.009\n",
            "[0.06310685] 0.225\n",
            "[0.22548865] 0.225\n",
            "[0.10012345] 0.005\n",
            "[0.11010946] 0.15\n",
            "[0.1157995] 0.3\n",
            "[0.07532404] 0.05\n",
            "[0.07441725] 0.05\n",
            "[0.19654901] 0.005\n",
            "[0.2720595] 0.1\n",
            "[0.2968967] 0.009\n",
            "[0.21865024] 0.05\n",
            "[0.19637679] 0.009\n",
            "[0.11391281] 0.03\n",
            "[0.2230217] 0.225\n",
            "[0.12560032] 0.1\n",
            "[0.22089235] 0.009\n",
            "[0.262499] 0.03\n",
            "[0.13554762] 0.05\n",
            "[0.21151404] 0.05\n",
            "[0.05781232] 0.05\n",
            "[0.25477767] 0.009\n",
            "[0.03788577] 0.009\n",
            "[0.08988176] 0.015\n",
            "[0.16537093] 0.225\n",
            "[0.2627133] 0.015\n",
            "[0.26807457] 0.015\n",
            "[0.11138602] 0.015\n",
            "[0.21170102] 0.3\n",
            "[0.13261391] 0.015\n",
            "[0.10274647] 0.225\n",
            "[0.12187915] 0.1\n",
            "[0.15047644] 0.005\n",
            "[0.09624667] 0.015\n",
            "[0.2719937] 0.015\n",
            "[0.14473273] 0.15\n",
            "[0.23443727] 0.005\n",
            "[0.08678339] 0.225\n",
            "[0.22389214] 0.015\n",
            "[0.104946] 0.1\n",
            "[0.2644846] 0.1\n",
            "[0.1479158] 0.15\n",
            "[0.1809075] 0.009\n",
            "[0.09484436] 0.05\n",
            "[0.2650137] 0.05\n",
            "[0.14649574] 0.05\n",
            "[0.1000476] 0.225\n",
            "[0.14913465] 0.15\n",
            "[0.14517657] 0.03\n",
            "[0.14486943] 0.009\n",
            "[0.2041235] 0.3\n",
            "[0.11332212] 0.15\n",
            "[0.1817932] 0.3\n",
            "[0.15329568] 0.009\n",
            "[0.29141256] 0.225\n",
            "[0.27368096] 0.05\n",
            "[0.11012872] 0.225\n",
            "[0.12065379] 0.225\n",
            "[0.09217159] 0.005\n",
            "[0.10786237] 0.1\n",
            "[0.27516264] 0.005\n",
            "[0.05352016] 0.15\n",
            "[0.15338086] 0.03\n",
            "[0.09419261] 0.15\n",
            "[0.13577573] 0.009\n",
            "[0.12630422] 0.005\n",
            "[0.05912887] 0.009\n",
            "[0.06632535] 0.1\n",
            "[0.14848395] 0.1\n",
            "[0.25335324] 0.1\n",
            "[0.2284274] 0.225\n",
            "[0.10411768] 0.005\n",
            "[0.23552026] 0.03\n",
            "[0.05596261] 0.15\n",
            "[0.30608213] 0.009\n",
            "[0.28994718] 0.3\n",
            "[0.07517545] 0.15\n",
            "[0.25726095] 0.03\n",
            "[0.21029942] 0.225\n",
            "[0.27632916] 0.015\n",
            "[0.26861572] 0.3\n",
            "[0.10248311] 0.009\n",
            "[0.16688313] 0.015\n",
            "[0.26007622] 0.015\n",
            "[0.2339604] 0.3\n",
            "[0.09561257] 0.009\n",
            "[0.262827] 0.015\n",
            "[0.11896272] 0.005\n",
            "[0.06690283] 0.05\n",
            "[0.26401165] 0.015\n",
            "[0.15741484] 0.009\n",
            "[0.29351094] 0.03\n",
            "[0.28032538] 0.03\n",
            "[0.2907858] 0.05\n",
            "[0.16155167] 0.009\n",
            "[0.2742965] 0.3\n",
            "[0.0611739] 0.015\n",
            "[0.2710378] 0.015\n",
            "[0.1008126] 0.009\n",
            "[0.11612748] 0.15\n",
            "[0.23464851] 0.1\n",
            "[0.07218726] 0.009\n",
            "[0.17211662] 0.225\n",
            "[0.06795688] 0.225\n",
            "[0.24306963] 0.225\n",
            "[0.3008349] 0.015\n",
            "[0.26396838] 0.009\n",
            "[0.27746558] 0.05\n",
            "[0.07316856] 0.1\n",
            "[0.29591456] 0.05\n",
            "[0.09096338] 0.05\n",
            "[0.29762983] 0.3\n",
            "[0.04893093] 0.015\n",
            "[0.30973923] 0.005\n",
            "[0.2163779] 0.005\n",
            "[0.16105394] 0.15\n",
            "[0.12409924] 0.1\n",
            "[0.26308358] 0.225\n",
            "[0.2297344] 0.225\n",
            "[0.06020068] 0.015\n",
            "[0.29485372] 0.225\n",
            "[0.3003047] 0.009\n",
            "[0.23547728] 0.03\n",
            "[0.06040765] 0.05\n",
            "[0.29641405] 0.05\n",
            "[0.12025841] 0.005\n",
            "[0.09212388] 0.005\n",
            "[0.25687522] 0.3\n",
            "[0.08051865] 0.015\n",
            "[0.26197913] 0.15\n",
            "[0.0656109] 0.005\n",
            "[0.06227978] 0.225\n",
            "[0.12535287] 0.1\n",
            "[0.09631969] 0.009\n",
            "[0.14357866] 0.15\n",
            "[0.1898459] 0.15\n",
            "[0.14954008] 0.009\n",
            "[0.20440634] 0.3\n",
            "[0.13793094] 0.1\n",
            "[0.13809605] 0.225\n",
            "[0.12011389] 0.3\n",
            "[0.07021816] 0.15\n",
            "[0.23536934] 0.1\n",
            "[0.25417545] 0.015\n",
            "[0.26229453] 0.005\n",
            "[0.10712586] 0.1\n",
            "[0.22164421] 0.3\n",
            "[0.13595997] 0.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inception Network"
      ],
      "metadata": {
        "id": "HrhjUXNAux-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# example of creating a CNN with an efficient inception module\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        " \n",
        "# function for creating a projected inception module\n",
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "\t# 1x1 conv\n",
        "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
        "\tpool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
        "\t# concatenate filters, assumes filters/channels last\n",
        "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "\treturn layer_out\n",
        " \n",
        "# define model input\n",
        "visible = Input(shape=(256, 256, 3))\n",
        "# add inception block 1\n",
        "layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
        "# add inception block 1\n",
        "layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
        "# create model\n",
        "model = Model(inputs=visible, outputs=layer)\n",
        "# summarize model\n",
        "model.summary()\n",
        "# plot model architecture\n",
        "plot_model(model, show_shapes=True, to_file='inception_module.png')"
      ],
      "metadata": {
        "id": "cek35__8O3rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OnnRWWUeO3nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iv9G_FtrO3gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "be7gW6NeO3dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0fzPnw1IO3Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MaSRVgEmO3WV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}